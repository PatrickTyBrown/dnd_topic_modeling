{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2E032_4_3.json\n"
     ]
    }
   ],
   "source": [
    "dir = 'data/aligned data/c=4'\n",
    "choice = random.choice(os.listdir(dir))\n",
    "print(choice)\n",
    "f = open(dir+'/'+choice)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CHUNK', 'ALIGNMENT', 'TURNS'])\n",
      "dict_keys(['NAMES', 'UTTERANCES', 'NUMBER'])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].keys())\n",
    "print(data[5]['TURNS'][0].keys())\n",
    "# print(data[5]['TURNS'][0]['UTTERANCES'])\n",
    "# print(' '.join(data[5]['TURNS'][0]['UTTERANCES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2612, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello everyone, and welcome to tonight's episo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's what we do!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's Dungeons &amp; Dragons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You will find out, Liam. He who ran it earlier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Bonegrinder.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Hello everyone, and welcome to tonight's episo...\n",
       "1                                 That's what we do!\n",
       "2                         What's Dungeons & Dragons?\n",
       "3  You will find out, Liam. He who ran it earlier...\n",
       "4                                   The Bonegrinder."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df(data=data):\n",
    "    list_of_text = []\n",
    "    for x in data:\n",
    "        for y in x['TURNS']:\n",
    "            text = ' '.join(y['UTTERANCES'])\n",
    "            list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df\n",
    "df = create_df(data=data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1E035_4_3.json\n",
      "C1E052_4_1.json\n",
      "C1E011_4_0.json\n",
      "C1E013_4_2.json\n",
      "C2E046_4_1.json\n",
      "C1E104_4_2.json\n",
      "C1E061_4_3.json\n",
      "C1E095_4_1.json\n",
      "C1E064_4_2.json\n",
      "C1E109_4_0.json\n",
      "(10242, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, and good evening everyone, to tonight's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me and Marisha have been Loot Crate--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--purveyors for like three years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But they've been awesome enough and interested...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leeloo Dallas Multipass!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Hello, and good evening everyone, to tonight's...\n",
       "1              Me and Marisha have been Loot Crate--\n",
       "2                  --purveyors for like three years.\n",
       "3  But they've been awesome enough and interested...\n",
       "4                           Leeloo Dallas Multipass!"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df_multi(n):\n",
    "    list_of_text = []\n",
    "    dir = 'data/aligned data/c=4'\n",
    "\n",
    "    for i in range(n):\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "\n",
    "        for x in data:\n",
    "            for y in x['TURNS']:\n",
    "                text = ' '.join(y['UTTERANCES'])\n",
    "                list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df\n",
    "df = create_df_multi(5)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10242, 8116)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = TfidfVectorizer(stop_words={'english'}, \n",
    "    max_df=0.005,\n",
    "    min_df=0.00001,\n",
    "    # norm='l1',\n",
    "    )\n",
    "doc_vec = cv.fit_transform(df[0])\n",
    "doc_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10242, 4587)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words={'english'}, \n",
    "    max_df=0.005,\n",
    "    min_df=0.0001,\n",
    "    # norm='l1',\n",
    "    )\n",
    "doc_vec = cv.fit_transform(df[0])\n",
    "doc_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8116, 10242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10232</th>\n",
       "      <th>10233</th>\n",
       "      <th>10234</th>\n",
       "      <th>10235</th>\n",
       "      <th>10236</th>\n",
       "      <th>10237</th>\n",
       "      <th>10238</th>\n",
       "      <th>10239</th>\n",
       "      <th>10240</th>\n",
       "      <th>10241</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zoning</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoomf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooming</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zopher</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zorro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9      \\\n",
       "zoning     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zoomf      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zooming    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zopher     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zorro      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         ...  10232  10233  10234  10235  10236  10237  10238  10239  10240  \\\n",
       "zoning   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zoomf    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zooming  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zopher   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zorro    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         10241  \n",
       "zoning     0.0  \n",
       "zoomf      0.0  \n",
       "zooming    0.0  \n",
       "zopher     0.0  \n",
       "zorro      0.0  \n",
       "\n",
       "[5 rows x 10242 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df = pd.DataFrame(doc_vec.toarray().transpose(),\n",
    "                   index=cv.get_feature_names())\n",
    "print(tf_df.shape)\n",
    "tf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_components = 50\n",
    "nmf_5 = NMF(n_components=n_components)\n",
    "topics = nmf_5.fit_transform(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 20\n",
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_components = 10\n",
    "nmf_5 = NMF(n_components=n_components)\n",
    "topics = nmf_5.fit_transform(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'll', 'was', 'get', 'they', 'did', 'know', 'don', 'yes', 'no']\n",
      "['know', 'she', 'like', 'was', 'my', 'well', 'they', 'laughter', 'did', 'yes']\n",
      "['my', 'want', 'if', 'like', 'here', 'll', 'they', 'get', 'don', 'know']\n",
      "['care', 'trust', 'worry', 'vecna', 'why', 'how', 'yes', 'no', 'don', 'know']\n",
      "['die', 'use', 'gosh', 'turn', 'know', 'fuck', 'laughter', 'thank', 'my', 'god']\n",
      "['why', 'know', 'me', 'laughter', 'get', 'say', 'how', 'my', 'god', 'did']\n",
      "['like', 'thing', 'know', 'really', 'well', 'she', 'was', 'laughter', 'did', 'good']\n",
      "['20', 'she', 'does', 'they', 'well', 'sorry', 'shit', 'like', 'was', 'laughter']\n",
      "['good', 'did', 'points', 'want', 'an', 'ahead', 'damage', 'roll', 'make', 'check']\n",
      "['roll', 'know', 'let', 'good', 'here', 'make', 'check', 'get', 'll', 'laughter']\n",
      "['think', 'us', 'sure', 'them', 'if', 'good', 'laughter', 'don', 'get', 'want']\n",
      "['say', 'if', 'don', 'fine', 'like', 'take', 'let', 'me', 'well', 'll']\n",
      "['them', 'take', 'good', 'say', 'fine', 'did', 'think', 'don', 'll', 'they']\n",
      "['who', 'an', 'thank', 'see', 'perception', 'like', 'they', 'me', 'make', 'check']\n",
      "['good', 'roll', 'here', 'think', 'natural', 'get', '20', 'let', 'me', 'don']\n",
      "['know', 'were', 'want', 'them', 'really', 'thank', 'me', 'let', 'well', 'they']\n",
      "['me', 'guys', 'get', 'amazing', 'know', '20', 'thank', 'll', 'want', 'was']\n",
      "['her', 'want', 'points', 'take', 'laughter', 'damage', 'how', '20', 'pike', 'here']\n",
      "['20', 'much', 'shit', 'guys', 'roll', 'really', 'don', 'thank', 'well', 'here']\n",
      "['damage', 'hit', 'much', 'guys', 'they', 'would', 'me', 'how', 'like', 'thank']\n"
     ]
    }
   ],
   "source": [
    "def get_top_terms(topic, n_terms, nmf=nmf_5, topics=topics, terms=cv.get_feature_names_out()):\n",
    "    # get the topic components (i.e., term weights)\n",
    "    # components = nmf.components_[topic, :]\n",
    "    components = topics[:,topic]\n",
    "\n",
    "    # get term indices, sorted (descending) by topic weights\n",
    "    top_term_indices = components.argsort()[-n_terms:]\n",
    "    \n",
    "    # use the `terms` array to get the actual top terms\n",
    "    top_terms = np.array(terms)[top_term_indices]\n",
    "    \n",
    "    return top_terms.tolist()\n",
    "\n",
    "for x in range(n_components):\n",
    "    print(get_top_terms(x,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00', '10', '100', '10d6', '11', '12', '120', '127', '13', '1350',\n",
       "       ...\n",
       "       'yup', 'zanror', 'zenith', 'zenwick', 'zephra', 'zero', 'zombie',\n",
       "       'zone', 'zoomf', 'zopher'],\n",
       "      dtype='object', length=4587)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6849,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10242)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_5.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4587, 10)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6849, 7310)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('metis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279e2d64b6cb4063ab7cfccb2020b604cfa41abe39379e7173718ec353138e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
