{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "### Without Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 25 #Topics To generate\n",
    "n = 20 #Transcripts to use\n",
    "max_df=0.01\n",
    "min_df=0.0001\n",
    "n_terms = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_multi(n=25):\n",
    "    list_of_text = []\n",
    "    dir = 'data/aligned data/c=4'\n",
    "\n",
    "    files = [filename for filename in os.listdir(dir)]\n",
    "    sampled_files = random.choices(files,k=n)\n",
    "\n",
    "    for filename in sampled_files:\n",
    "        # choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+filename)\n",
    "        data = json.load(f)\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "\n",
    "        for x in data:\n",
    "            for y in x['TURNS']:\n",
    "                text = ' '.join(y['UTTERANCES'])\n",
    "                list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51137, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's up, GenCon?! (cheering)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's a lot of people. How you guys doing? (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh my god. Send me the bill for your plane tic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know what's up, brother. Thank you guys fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is happening?! We are alive at the best m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                     What's up, GenCon?! (cheering)\n",
       "1  That's a lot of people. How you guys doing? (c...\n",
       "2  Oh my god. Send me the bill for your plane tic...\n",
       "3  You know what's up, brother. Thank you guys fo...\n",
       "4  What is happening?! We are alive at the best m..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df_multi(n)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Count Vectorizer\n",
    "- Tfidf Vectorizer\n",
    "\n",
    "Use both with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51137, 5113)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51127</th>\n",
       "      <th>51128</th>\n",
       "      <th>51129</th>\n",
       "      <th>51130</th>\n",
       "      <th>51131</th>\n",
       "      <th>51132</th>\n",
       "      <th>51133</th>\n",
       "      <th>51134</th>\n",
       "      <th>51135</th>\n",
       "      <th>51136</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zenwick</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziggurat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      \\\n",
       "zenwick     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zero        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ziggurat    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombie      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zone        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "          9      ...  51127  51128  51129  51130  51131  51132  51133  51134  \\\n",
       "zenwick     0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zero        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ziggurat    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombie      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zone        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "          51135  51136  \n",
       "zenwick     0.0    0.0  \n",
       "zero        0.0    0.0  \n",
       "ziggurat    0.0    0.0  \n",
       "zombie      0.0    0.0  \n",
       "zone        0.0    0.0  \n",
       "\n",
       "[5 rows x 51137 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf=TfidfVectorizer(stop_words='english',max_df=.7,min_df=2,token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "tfidf_sparse = tfidf.fit_transform(df[0])\n",
    "print(tfidf_sparse.shape)\n",
    "tfidf_df = pd.DataFrame(tfidf_sparse.toarray().transpose(),\n",
    "                   index=tfidf.get_feature_names_out())\n",
    "tfidf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51137, 5113)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51127</th>\n",
       "      <th>51128</th>\n",
       "      <th>51129</th>\n",
       "      <th>51130</th>\n",
       "      <th>51131</th>\n",
       "      <th>51132</th>\n",
       "      <th>51133</th>\n",
       "      <th>51134</th>\n",
       "      <th>51135</th>\n",
       "      <th>51136</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zenwick</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziggurat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      \\\n",
       "zenwick       0      0      0      0      0      0      0      0      0   \n",
       "zero          0      0      0      0      0      0      0      0      0   \n",
       "ziggurat      0      0      0      0      0      0      0      0      0   \n",
       "zombie        0      0      0      0      0      0      0      0      0   \n",
       "zone          0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "          9      ...  51127  51128  51129  51130  51131  51132  51133  51134  \\\n",
       "zenwick       0  ...      0      0      0      0      0      0      0      0   \n",
       "zero          0  ...      0      0      0      0      0      0      0      0   \n",
       "ziggurat      0  ...      0      0      0      0      0      0      0      0   \n",
       "zombie        0  ...      0      0      0      0      0      0      0      0   \n",
       "zone          0  ...      0      0      0      0      0      0      0      0   \n",
       "\n",
       "          51135  51136  \n",
       "zenwick       0      0  \n",
       "zero          0      0  \n",
       "ziggurat      0      0  \n",
       "zombie        0      0  \n",
       "zone          0      0  \n",
       "\n",
       "[5 rows x 51137 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "cv_sparse = cv.fit_transform(df[0])\n",
    "print(cv_sparse.shape)\n",
    "cv_df = pd.DataFrame(cv_sparse.toarray().transpose(),\n",
    "                   index=cv.get_feature_names_out())\n",
    "cv_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_terms(n_components, topics, terms, n_terms = 10):\n",
    "    for x in range(n_components):\n",
    "        topic = x\n",
    "        components = topics[:,topic]\n",
    "        top_term_indices = components.argsort()[-n_terms:]\n",
    "        top_terms = np.array(terms)[top_term_indices]\n",
    "        \n",
    "        print(f'Topic {x}:\\t{top_terms.tolist()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['eyes', 'long', 'center', 'large', 'city', 'past', 'brought', 'dark', 'hear', 'begin']\n",
      "Topic 1:\t['week', 'emon', 'family', 'town', 'vox', 'dragon', 'machina', 'party', 'percy', 'city']\n",
      "Topic 2:\t['comes', 'eyes', 'light', 'flash', 'dark', 'darkness', 'feel', 'ground', 'vision', 'thunder']\n",
      "Topic 3:\t['twitch', 'creatures', 'players', 'role', 'tonight', 'critical', 'game', 'cool', 'episode', 'week']\n",
      "Topic 4:\t['powerful', 'creatures', 'encounter', 'seen', 'players', 'family', 'cool', 'battle', 'pike', 'percy']\n",
      "Topic 5:\t['years', 'scanlan', 'episode', 'left', 'arm', 'vox', 'family', 'machina', 'pike', 'percy']\n",
      "Topic 6:\t['house', 'gnome', 'swamp', 'herd', 'wilhand', 'scanlan', 'great', 'life', 'left', 'pike']\n",
      "Topic 7:\t['comes', 'soon', 'strength', 'dragon', 'coming', 'immediately', 'muscle', 'face', 'swing', 'arm']\n",
      "Topic 8:\t['mighty', 'northward', 'past', 'cut', 'safe', 'muscle', 'swing', 'percy', 'swamp', 'arm']\n",
      "Topic 9:\t['best', 'chamber', 'fantastic', 'family', 'life', 'episode', 'week', 'hand', 'begin', 'pike']\n",
      "Topic 10:\t['vision', 'sound', 'discovered', 'head', 'pike', 'hear', 'thunder', 'emon', 'party', 'dragon']\n",
      "Topic 11:\t['bars', 'body', 'house', 'small', 'pull', 'begins', 'devil', 'chamber', 'begin', 'percy']\n",
      "Topic 12:\t['eventually', 'center', 'structure', 'percy', 'better', 'coming', 'mountain', 'city', 'temple', 'begin']\n",
      "Topic 13:\t['body', 'small', 'satchel', 'city', 'temple', 'chains', 'bars', 'long', 'devil', 'chamber']\n",
      "Topic 14:\t['begins', 'information', 'body', 'chains', 'path', 'shit', 'feel', 'city', 'begin', 'scanlan']\n",
      "Topic 15:\t['mind', 'giant', 'strange', 'energy', 'form', 'center', 'temple', 'door', 'feel', 'scanlan']\n",
      "Topic 16:\t['left', 'city', 'moment', 'shit', 'inside', 'hand', 'chamber', 'devil', 'open', 'door']\n",
      "Topic 17:\t['forest', 'chamber', 'coming', 'love', 'week', 'small', 'day', 'mountain', 'long', 'scanlan']\n",
      "Topic 18:\t['idea', 'help', 'stone', 'advancing', 'obstacle', 'courses', 'moment', 'path', 'shit', 'better']\n",
      "Topic 19:\t['man', 'hear', 'vax', 'streets', 'moment', 'better', 'feel', 'shit', 'door', 'dragon']\n",
      "Topic 20:\t['tuesday', 'master', 'hearts', 'account', 'begin', 'currently', 'free', 'twitch', 'scanlan', 'door']\n",
      "Topic 21:\t['watch', 'party', 'moment', 'seen', 'pike', 'shit', 'sorry', 'hand', 'door', 'begin']\n",
      "Topic 22:\t['week', 'vision', 'energy', 'keyleth', 'form', 'open', 'temple', 'city', 'vax', 'door']\n",
      "Topic 23:\t['feel', 'vex', 'elemental', 'air', 'plus', 'vax', 'spell', 'long', 'keyleth', 'sorry']\n",
      "Topic 24:\t['run', 'throw', 'great', 'seen', 'far', 'head', 'sorry', 'feel', 'door', 'begin']\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['cheering', 'pike', 'doesn', 'armor', 'seven', 'natural', 'definitely', 'second', 'plus', 'hits']\n",
      "Topic 1:\t['didn', 'percy', 'fucking', 'plus', 'fuck', 'pike', 'holy', 'sorry', 'god', 'shit']\n",
      "Topic 2:\t['dice', 'plus', 'fine', 'awesome', 'tell', 'love', 'die', 'laughs', 'damn', 'god']\n",
      "Topic 3:\t['pike', 'rolled', 'second', 'percy', 'great', 'strength', 'seven', 'natural', 'sorry', 'plus']\n",
      "Topic 4:\t['fjord', 'vax', 'fine', 'scanlan', 'keyleth', 'percy', 'didn', 'mean', 'pike', 'sorry']\n",
      "Topic 5:\t['cool', 'didn', 'scanlan', 'probably', 'natural', 'great', 'laughs', 'percy', 'pike', 'fine']\n",
      "Topic 6:\t['mean', 'throw', 'vex', 'keyleth', 'vax', 'cool', 'laughs', 'scanlan', 'percy', 'pike']\n",
      "Topic 7:\t['gold', 'ooh', 'advantage', 'great', 'fucking', 'second', 'rolled', 'cheering', 'laughs', 'natural']\n",
      "Topic 8:\t['pretty', 'nice', 'idea', 'man', 'sorry', 'fuck', 'cool', 'didn', 'great', 'laughs']\n",
      "Topic 9:\t['ends', 'gold', 'keyleth', 'mean', 'run', 'scanlan', 'cool', 'vex', 'vax', 'percy']\n",
      "Topic 10:\t['hey', 'feel', 'fucking', 'scanlan', 'man', 'pretty', 'mean', 'idea', 'cool', 'great']\n",
      "Topic 11:\t['stay', 'saving', 'fuck', 'hold', 'probably', 'keyleth', 'throw', 'pretty', 'mean', 'cool']\n",
      "Topic 12:\t['far', 'vax', 'didn', 'door', 'scanlan', 'saving', 'perception', 'fuck', 'throw', 'mean']\n",
      "Topic 13:\t['run', 'disadvantage', 'better', 'hold', 'saving', 'throw', 'advantage', 'rolled', 'scanlan', 'perception']\n",
      "Topic 14:\t['feel', 'door', 'run', 'strength', 'dexterity', 'fuck', 'wisdom', 'constitution', 'saving', 'throw']\n",
      "Topic 15:\t['better', 'guy', 'far', 'doesn', 'action', 'probably', 'run', 'scanlan', 'fucking', 'fuck']\n",
      "Topic 16:\t['fine', 'great', 'pike', 'cool', 'percy', 'saving', 'perception', 'throw', 'mean', 'fuck']\n",
      "Topic 17:\t['hey', 'feel', 'true', 'vex', 'seven', 'better', 'advantage', 'rolled', 'scanlan', 'didn']\n",
      "Topic 18:\t['spell', 'second', 'nice', 'fucking', 'mean', 'bonus', 'action', 'hold', 'scanlan', 'rolled']\n",
      "Topic 19:\t['advantage', 'yep', 'vex', 'tell', 'hold', 'said', 'probably', 'gold', 'didn', 'rolled']\n",
      "Topic 20:\t['said', 'gold', 'disadvantage', 'vax', 'scanlan', 'advantage', 'bonus', 'hold', 'action', 'didn']\n",
      "Topic 21:\t['fucking', 'action', 'better', 'man', 'tell', 'pieces', 'second', 'scanlan', 'probably', 'gold']\n",
      "Topic 22:\t['fuck', 'idea', 'said', 'bonus', 'rolled', 'didn', 'yep', 'gold', 'action', 'far']\n",
      "Topic 23:\t['true', 'man', 'ooh', 'idea', 'tell', 'pretty', 'bad', 'advantage', 'far', 'probably']\n",
      "Topic 24:\t['open', 'perception', 'said', 'idea', 'start', 'vax', 'door', 'bonus', 'action', 'probably']\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['worth', 'checks', 'add', 'troll', 'stealth', 'die', 'strike', 'kill', 'talk', 'second']\n",
      "Topic 1:\t['level', 'care', 'using', 'dexterity', 'wow', 'wouldn', 'definitely', 'white', 'movement', 'probably']\n",
      "Topic 2:\t['read', 'slow', 'ago', 'anybody', 'watching', 'later', 'sitting', 'live', 'amazing', 'closer']\n",
      "Topic 3:\t['glad', 'rolling', 'cover', 'j', 'mon', 'piece', 'happening', 'heading', 'manage', 'kima']\n",
      "Topic 4:\t['smoke', 'dangerous', 'cassandra', 'shoot', 'power', 'constitution', 'happy', 'happened', 'table', 'tiberius']\n",
      "Topic 5:\t['main', 'investigation', 'heal', 'hide', 'hour', 'correct', 'yep', 'laughs', 'cool', 'plus']\n",
      "Topic 6:\t['platform', 'invisible', 'shift', 'effect', 'somebody', 'frumpkin', 'happens', 'question', 'rolled', 'fjord']\n",
      "Topic 7:\t['mouth', 'understand', 'singing', 'jump', 'stairs', 'attention', 'chains', 'home', 'metal', 'getting']\n",
      "Topic 8:\t['rough', 'meet', 'deal', 'weapon', 'drink', 'bunch', 'ice', 'nope', 'play', 'range']\n",
      "Topic 9:\t['sand', 'finish', 'ring', 'emon', 'weird', 'party', 'fight', 'awesome', 'couple', 'thought']\n",
      "Topic 10:\t['moves', 'surprise', 'burst', 'rocks', 'stupid', 'recognize', 'rushing', 'stands', 'wish', 'saying']\n",
      "Topic 11:\t['counting', 'finger', 'cure', 'travis', 'quietly', 'today', 'technically', 'carpet', 'ceiling', 'heard']\n",
      "Topic 12:\t['muscle', 'buy', 'ah', 'molly', 'unfortunately', 'gonna', 'arm', 'seven', 'bonus', 'trinket']\n",
      "Topic 13:\t['visual', 'pulling', 'vision', 'pit', 'glass', 'sword', 'continue', 'steps', 'hard', 'fuck']\n",
      "Topic 14:\t['beach', 'flame', 'easy', 'feeling', 'wonderful', 'modifier', 'total', 'times', 'dagger', 'bring']\n",
      "Topic 15:\t['trap', 'draconia', 'whispers', 'acid', 'sent', 'appears', 'matt', 'arrow', 'sleep', 'keyleth']\n",
      "Topic 16:\t['touch', 'initiative', 'cause', 'bed', 'starts', 'ability', 'starting', 'nott', 'day', 'hits']\n",
      "Topic 17:\t['lower', 'oil', 'lost', 'bolt', 'righty', 'walking', 'ooh', 'saw', 'grab', 'percy']\n",
      "Topic 18:\t['fact', 'wants', 'hope', 'holy', 'stand', 'healing', 'gilmore', 'cheering', 'nice', 'love']\n",
      "Topic 19:\t['grasp', 'jesus', 'regular', 'athletics', 'horn', 'playing', 'rage', 'mark', 'laugh', 'spell']\n",
      "Topic 20:\t['roof', 'doorway', 'tal', 'blow', 'beautiful', 'miss', 'sneak', 'ones', 'means', 'book']\n",
      "Topic 21:\t['punch', 'dwarf', 'entrance', 'dc', 'horses', 'totally', 'told', 'heart', 'damn', 'traps']\n",
      "Topic 22:\t['funny', 'fingers', 'skin', 'anymore', 'important', 'aren', 'wrong', 'sounds', 'round', 'stone']\n",
      "Topic 23:\t['covered', 'boy', 'hi', 'gnome', 'world', 'whitestone', 'life', 'guy', 'hold', 'action']\n",
      "Topic 24:\t['piercing', 'cage', 'excited', 'won', 'fly', 'plan', 'wisdom', 'hey', 'stay', 'mean']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['hmm', 'whisper', 'punch', 'chirping', 'cage', 'shirts', 'stupid', 'checks', 'whoa', 'yep']\n",
      "Topic 1:\t['seven', 'zero', 'cat', 'map', 'intelligence', 'draconia', 'technically', 'dc', 'word', 'fair']\n",
      "Topic 2:\t['write', 'works', 'hell', 'heal', 'uh', 'order', 'excited', 'potions', 'ask', 'beau']\n",
      "Topic 3:\t['hate', 'enchantment', 'opportunity', 'certainly', 'double', 'hi', 'singing', 'wasn', 'insight', 'wow']\n",
      "Topic 4:\t['forgot', 'true', 'travis', 'prone', 'surprise', 'mansion', 'kiri', 'counting', 'constitution', 'gonna']\n",
      "Topic 5:\t['news', 'hits', 'horse', 'trouble', 'tail', 'bludgeoning', 'man', 'bird', 'straight', 'ugh']\n",
      "Topic 6:\t['shouldn', 'missed', 'playing', 'rod', 'fun', 'lockheed', 'perfect', 'acid', 'caleb', 'said']\n",
      "Topic 7:\t['quietly', 'broom', 'checking', 'common', 'thinking', 'hunter', 'buy', 'care', 'persuasion', 'trinket']\n",
      "Topic 8:\t['ashari', 'dwarf', 'groans', 'climb', 'natural', 'gasps', 'misses', 'matt', 'fly', 'advantage']\n",
      "Topic 9:\t['goddamn', 'sing', 'obviously', 'sharpshooter', 'course', 'dick', 'box', 'carpet', 'bag', 'dagger']\n",
      "Topic 10:\t['luck', 'jesus', 'horses', 'trust', 'happy', 'frumpkin', 'ah', 'stealth', 'ooh', 'kill']\n",
      "Topic 11:\t['bed', 'death', 'happening', 'distance', 'weird', 'range', 'saying', 'movement', 'night', 'day']\n",
      "Topic 12:\t['pocket', 'slashing', 'beach', 'deception', 'ja', 'shit', 'wonderful', 'hole', 'add', 'wisdom']\n",
      "Topic 13:\t['noises', 'caduceus', 'greater', 'cave', 'ashley', 'happened', 'regular', 'worst', 'minus', 'window']\n",
      "Topic 14:\t['oil', 'buddy', 'unless', 'yay', 'potion', 'tary', 'extra', 'invisible', 'jester', 'safe']\n",
      "Topic 15:\t['crying', 'listen', 'credit', 'flying', 'inspiration', 'dm', 'bomb', 'arcana', 'crazy', 'guess']\n",
      "Topic 16:\t['grit', 'radiant', 'spells', 'funny', 'dog', 'trap', 'eat', 'deal', 'plan', 'traps']\n",
      "Topic 17:\t['additional', 'supposed', 'concentration', 'hurt', 'miss', 'troll', 'dexterity', 'totally', 'thanks', 'nope']\n",
      "Topic 18:\t['golem', 'split', 'glad', 'blow', 'assume', 'happens', 'modifier', 'rage', 'sneak', 'perception']\n",
      "Topic 19:\t['anybody', 'whispering', 'laughing', 'hang', 'stick', 'rolls', 'initiative', 'read', 'boy', 'question']\n",
      "Topic 20:\t['diamonds', 'nice', 'athletics', 'aw', 'guy', 'ring', 'shoot', 'healing', 'shot', 'laughs']\n",
      "Topic 21:\t['reading', 'important', 'home', 'hupperdook', 'reaction', 'allura', 'drink', 'gilmore', 'righty', 'correct']\n",
      "Topic 22:\t['wouldn', 'drunk', 'sleep', 'afraid', 'smart', 'real', 'anymore', 'investigation', 'total', 'rolled']\n",
      "Topic 23:\t['shut', 'fireball', 'jeez', 'psychic', 'cute', 'clarota', 'remember', 'problem', 'fine', 'whispers']\n",
      "Topic 24:\t['pop', 'doty', 'drop', 'save', 'wants', 'laugh', 'dice', 'molly', 'bonus', 'god']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['eyes', 'center', 'brought', 'past', 'long', 'large', 'hear', 'dark', 'city', 'begin']\n",
      "Topic 1:\t['family', 'town', 'episode', 'dragon', 'week', 'vox', 'party', 'machina', 'percy', 'city']\n",
      "Topic 2:\t['comes', 'eyes', 'light', 'flash', 'darkness', 'dark', 'feel', 'ground', 'vision', 'thunder']\n",
      "Topic 3:\t['twitch', 'creatures', 'players', 'role', 'tonight', 'critical', 'game', 'cool', 'episode', 'week']\n",
      "Topic 4:\t['powerful', 'great', 'encounter', 'players', 'seen', 'cool', 'family', 'battle', 'pike', 'percy']\n",
      "Topic 5:\t['years', 'prime', 'episode', 'left', 'arm', 'vox', 'family', 'pike', 'machina', 'percy']\n",
      "Topic 6:\t['house', 'gnome', 'swamp', 'herd', 'wilhand', 'scanlan', 'great', 'life', 'left', 'pike']\n",
      "Topic 7:\t['attacks', 'dragon', 'soon', 'strength', 'coming', 'immediately', 'muscle', 'face', 'swing', 'arm']\n",
      "Topic 8:\t['mighty', 'past', 'northward', 'cut', 'safe', 'muscle', 'swing', 'percy', 'arm', 'swamp']\n",
      "Topic 9:\t['seen', 'second', 'moment', 'chamber', 'far', 'episode', 'week', 'hand', 'begin', 'pike']\n",
      "Topic 10:\t['head', 'hear', 'episode', 'thunder', 'life', 'emon', 'week', 'party', 'pike', 'dragon']\n",
      "Topic 11:\t['body', 'bars', 'pull', 'house', 'small', 'begins', 'devil', 'chamber', 'begin', 'percy']\n",
      "Topic 12:\t['eventually', 'better', 'structure', 'coming', 'percy', 'feel', 'city', 'mountain', 'temple', 'begin']\n",
      "Topic 13:\t['body', 'satchel', 'small', 'chains', 'temple', 'city', 'bars', 'long', 'devil', 'chamber']\n",
      "Topic 14:\t['devil', 'moment', 'path', 'chains', 'body', 'shit', 'feel', 'city', 'begin', 'scanlan']\n",
      "Topic 15:\t['pike', 'mind', 'form', 'strange', 'giant', 'temple', 'center', 'feel', 'scanlan', 'door']\n",
      "Topic 16:\t['lady', 'pike', 'dark', 'driven', 'carries', 'dangerous', 'entire', 'run', 'seen', 'begin']\n",
      "Topic 17:\t['week', 'open', 'small', 'large', 'coming', 'chamber', 'day', 'mountain', 'long', 'scanlan']\n",
      "Topic 18:\t['cool', 'streets', 'devil', 'man', 'cast', 'face', 'pull', 'ground', 'city', 'hand']\n",
      "Topic 19:\t['sky', 'moment', 'shit', 'man', 'vax', 'devil', 'streets', 'feel', 'door', 'dragon']\n",
      "Topic 20:\t['hearts', 'open', 'free', 'account', 'pike', 'vax', 'twitch', 'begin', 'scanlan', 'door']\n",
      "Topic 21:\t['throw', 'place', 'vax', 'form', 'wall', 'stone', 'hear', 'scanlan', 'city', 'dragon']\n",
      "Topic 22:\t['gnome', 'far', 'light', 'shit', 'better', 'currently', 'pull', 'percy', 'stone', 'scanlan']\n",
      "Topic 23:\t['long', 'keyleth', 'light', 'begin', 'far', 'saving', 'plus', 'feel', 'throw', 'sorry']\n",
      "Topic 24:\t['council', 'town', 'high', 'currently', 'hits', 'long', 'stone', 'light', 'saving', 'throw']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['percy', 'pike', 'armor', 'doesn', 'seven', 'natural', 'definitely', 'second', 'plus', 'hits']\n",
      "Topic 1:\t['mean', 'fucking', 'fuck', 'percy', 'pike', 'holy', 'plus', 'sorry', 'god', 'shit']\n",
      "Topic 2:\t['dice', 'awesome', 'love', 'die', 'tell', 'fine', 'plus', 'laughs', 'damn', 'god']\n",
      "Topic 3:\t['fine', 'second', 'strength', 'great', 'pike', 'percy', 'seven', 'natural', 'sorry', 'plus']\n",
      "Topic 4:\t['vex', 'vax', 'scanlan', 'keyleth', 'fine', 'percy', 'didn', 'mean', 'pike', 'sorry']\n",
      "Topic 5:\t['door', 'throw', 'probably', 'scanlan', 'natural', 'great', 'laughs', 'percy', 'pike', 'fine']\n",
      "Topic 6:\t['totally', 'fjord', 'feel', 'hits', 'probably', 'didn', 'plus', 'shit', 'sorry', 'fine']\n",
      "Topic 7:\t['mean', 'didn', 'sorry', 'far', 'fuck', 'fjord', 'cool', 'plus', 'great', 'laughs']\n",
      "Topic 8:\t['fucking', 'keyleth', 'advantage', 'rolled', 'gold', 'second', 'great', 'cheering', 'laughs', 'natural']\n",
      "Topic 9:\t['pretty', 'far', 'perception', 'door', 'saving', 'cool', 'great', 'vax', 'throw', 'percy']\n",
      "Topic 10:\t['true', 'saving', 'probably', 'man', 'throw', 'pretty', 'idea', 'mean', 'cool', 'great']\n",
      "Topic 11:\t['god', 'plus', 'shit', 'natural', 'fine', 'sorry', 'idea', 'pike', 'percy', 'great']\n",
      "Topic 12:\t['plus', 'laughs', 'pretty', 'natural', 'fine', 'great', 'sorry', 'pike', 'percy', 'cool']\n",
      "Topic 13:\t['laughs', 'pike', 'vax', 'plus', 'natural', 'ooh', 'fine', 'cool', 'percy', 'mean']\n",
      "Topic 14:\t['advantage', 'hold', 'idea', 'vax', 'probably', 'scanlan', 'rolled', 'great', 'fuck', 'perception']\n",
      "Topic 15:\t['disadvantage', 'great', 'yep', 'constitution', 'wisdom', 'mean', 'advantage', 'perception', 'saving', 'throw']\n",
      "Topic 16:\t['bad', 'perception', 'cool', 'percy', 'guy', 'rolled', 'saving', 'mean', 'throw', 'fuck']\n",
      "Topic 17:\t['fucking', 'probably', 'better', 'disadvantage', 'man', 'didn', 'door', 'gold', 'rolled', 'scanlan']\n",
      "Topic 18:\t['man', 'tell', 'better', 'bad', 'advantage', 'rolled', 'nice', 'hey', 'pretty', 'didn']\n",
      "Topic 19:\t['cast', 'man', 'throw', 'vex', 'tell', 'bonus', 'hold', 'didn', 'action', 'scanlan']\n",
      "Topic 20:\t['bonus', 'true', 'action', 'hold', 'vex', 'advantage', 'keyleth', 'vax', 'door', 'rolled']\n",
      "Topic 21:\t['true', 'tell', 'hey', 'run', 'far', 'caleb', 'probably', 'hold', 'gold', 'rolled']\n",
      "Topic 22:\t['awesome', 'idea', 'action', 'love', 'pieces', 'yep', 'vax', 'run', 'far', 'gold']\n",
      "Topic 23:\t['better', 'doesn', 'disadvantage', 'probably', 'bonus', 'idea', 'didn', 'scanlan', 'action', 'far']\n",
      "Topic 24:\t['strength', 'feel', 'nott', 'tell', 'fjord', 'hey', 'bonus', 'man', 'action', 'advantage']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['devils', 'metal', 'various', 'gives', 'hear', 'begin', 'occasionally', 'chains', 'past', 'brought']\n",
      "Topic 1:\t['fantastic', 'gathered', 'central', 'information', 'best', 'beneath', 'decided', 'stack', 'far', 'city']\n",
      "Topic 2:\t['sound', 'fades', 'light', 'figure', 'flash', 'ground', 'dark', 'darkness', 'vision', 'thunder']\n",
      "Topic 3:\t['master', 'interesting', 'fight', 'powerful', 'game', 'battle', 'encounter', 'players', 'creatures', 'cool']\n",
      "Topic 4:\t['shirt', 'fun', 'welcome', 'tonight', 'thursday', 'game', 'episode', 'role', 'critical', 'week']\n",
      "Topic 5:\t['lady', 'town', 'castle', 'years', 'took', 'briarwoods', 'whitestone', 'briarwood', 'family', 'percy']\n",
      "Topic 6:\t['killed', 'heal', 'best', 'felt', 'great', 'wilhand', 'left', 'life', 'family', 'pike']\n",
      "Topic 7:\t['attacks', 'soon', 'strength', 'past', 'comes', 'face', 'coming', 'muscle', 'swing', 'arm']\n",
      "Topic 8:\t['merrow', 'northward', 'nein', 'mighty', 'journey', 'labenda', 'heading', 'house', 'safe', 'swamp']\n",
      "Topic 9:\t['dragon', 'head', 'worm', 'gathered', 'discovered', 'house', 'center', 'large', 'emon', 'party']\n",
      "Topic 10:\t['mansion', 'hopefully', 'vecna', 'managed', 'plane', 'power', 'machina', 'vox', 'trammels', 'left']\n",
      "Topic 11:\t['action', 'disadvantage', 'spell', 'end', 'dexterity', 'constitution', 'wisdom', 'plus', 'saving', 'throw']\n",
      "Topic 12:\t['said', 'second', 'driven', 'carries', 'dangerous', 'entire', 'run', 'far', 'long', 'seen']\n",
      "Topic 13:\t['begins', 'long', 'turns', 'body', 'satchel', 'chain', 'bars', 'chains', 'chamber', 'devil']\n",
      "Topic 14:\t['approach', 'range', 'structure', 'large', 'watch', 'base', 'eventually', 'begins', 'mountain', 'begin']\n",
      "Topic 15:\t['light', 'sky', 'eyes', 'energy', 'focus', 'form', 'center', 'dark', 'temple', 'feel']\n",
      "Topic 16:\t['step', 'open', 'inside', 'forest', 'area', 'large', 'currently', 'wall', 'small', 'stone']\n",
      "Topic 17:\t['voice', 'fellow', 'second', 'love', 'support', 'mother', 'sings', 'eye', 'gnome', 'scanlan']\n",
      "Topic 18:\t['taking', 'idea', 'help', 'advancing', 'courses', 'obstacle', 'moment', 'path', 'better', 'shit']\n",
      "Topic 19:\t['town', 'vox', 'bring', 'lost', 'life', 'kevdak', 'great', 'westruun', 'herd', 'dragon']\n",
      "Topic 20:\t['hearts', 'com', 'prime', 'account', 'free', 'tuesday', 'machina', 'tonight', 'twitch', 'episode']\n",
      "Topic 21:\t['kima', 'steps', 'takes', 'hits', 'second', 'face', 'pull', 'forward', 'blade', 'hand']\n",
      "Topic 22:\t['doorway', 'guards', 'dimension', 'iron', 'doors', 'opens', 'sorry', 'inside', 'open', 'door']\n",
      "Topic 23:\t['mother', 'half', 'elemental', 'elven', 'air', 'set', 'father', 'vex', 'vax', 'keyleth']\n",
      "Topic 24:\t['voices', 'air', 'dragon', 'sounds', 'slowly', 'voice', 'sound', 'distance', 'probably', 'hear']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=500)\n",
    "topics = nmf.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['doesn', 'seven', 'course', 'cheering', 'sneak', 'barely', 'armor', 'definitely', 'second', 'hits']\n",
      "Topic 1:\t['sighs', 'caleb', 'laugh', 'balls', 'went', 'ah', 'piece', 'fucking', 'holy', 'shit']\n",
      "Topic 2:\t['bad', 'kill', 'thought', 'amazing', 'dice', 'awesome', 'love', 'die', 'damn', 'god']\n",
      "Topic 3:\t['psychic', 'bonus', 'sneak', 'proficiency', 'total', 'level', 'modifier', 'strength', 'seven', 'plus']\n",
      "Topic 4:\t['tried', 'matt', 'caleb', 'laugh', 'fjord', 'buddy', 'thought', 'course', 'love', 'sorry']\n",
      "Topic 5:\t['stay', 'strength', 'temple', 'hand', 'vex', 'help', 'hi', 'ends', 'says', 'pike']\n",
      "Topic 6:\t['making', 'yep', 'shot', 'worry', 'dagger', 'taking', 'totally', 'guess', 'work', 'fine']\n",
      "Topic 7:\t['save', 'blood', 'fucking', 'row', 'history', 'ooh', 'groaning', 'second', 'cheering', 'natural']\n",
      "Topic 8:\t['awesome', 'start', 'stay', 'bear', 'true', 'quietly', 'currently', 'smart', 'worst', 'laughs']\n",
      "Topic 9:\t['trinket', 'seen', 'skull', 'bear', 'tiberius', 'wanted', 'love', 'ends', 'vex', 'percy']\n",
      "Topic 10:\t['plan', 'wow', 'seven', 'awesome', 'love', 'master', 'weapon', 'pretty', 'idea', 'great']\n",
      "Topic 11:\t['end', 'save', 'throws', 'disadvantage', 'strength', 'dexterity', 'constitution', 'wisdom', 'saving', 'throw']\n",
      "Topic 12:\t['keyleth', 'seven', 'stuff', 'ah', 'fun', 'sounds', 'awesome', 'stay', 'pretty', 'cool']\n",
      "Topic 13:\t['run', 'close', 'stay', 'stealth', 'idea', 'disadvantage', 'guess', 'doesn', 'lot', 'mean']\n",
      "Topic 14:\t['traps', 'better', 'guess', 'frumpkin', 'checks', 'investigation', 'passive', 'disadvantage', 'advantage', 'perception']\n",
      "Topic 15:\t['doesn', 'fjord', 'caleb', 'fucking', 'better', 'second', 'tell', 'feel', 'man', 'probably']\n",
      "Topic 16:\t['ah', 'help', 'friend', 'talking', 'gil', 'laugh', 'guy', 'fucking', 'run', 'fuck']\n",
      "Topic 17:\t['important', 'cheering', 'whispers', 'ends', 'long', 'laugh', 'idea', 'love', 'vex', 'scanlan']\n",
      "Topic 18:\t['idea', 'thought', 'wanted', 'hear', 'bad', 'plan', 'ask', 'kill', 'said', 'didn']\n",
      "Topic 19:\t['person', 'dash', 'hide', 'spell', 'holding', 'movement', 'cast', 'bonus', 'action', 'hold']\n",
      "Topic 20:\t['dc', 'wrong', 'investigation', 'vex', 'stealth', 'doesn', 'seven', 'advantage', 'disadvantage', 'rolled']\n",
      "Topic 21:\t['direction', 'distance', 'movement', 'everybody', 'gone', 'stay', 'pretty', 'end', 'run', 'far']\n",
      "Topic 22:\t['roughly', 'armor', 'party', 'pocket', 'diamonds', 'platinum', 'worth', 'run', 'pieces', 'gold']\n",
      "Topic 23:\t['wall', 'push', 'close', 'dimension', 'start', 'walk', 'inside', 'run', 'open', 'door']\n",
      "Topic 24:\t['near', 'ahlia', 'holding', 'hear', 'run', 'brings', 'ends', 'vex', 'keyleth', 'vax']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=200)\n",
    "topics = nmf.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('metis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279e2d64b6cb4063ab7cfccb2020b604cfa41abe39379e7173718ec353138e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
