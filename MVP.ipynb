{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DND Topic Modeling MVP\n",
    "\n",
    "****\n",
    "\n",
    "### Background\n",
    "- The client is looking to use Dnd session transcripts to inform their model/product design and improve customer experience. We are using Topic Modeling to better understand the trends that take place during a DnD session.\n",
    "\n",
    "****\n",
    "\n",
    "### Takeaways\n",
    "- With NMF:\n",
    "  - CV shows topics in the in game content (Settings, Actions, Characters..)\n",
    "  - TFIDF shows more macro topics (Sessions introductions, Rolling, Attacking, Meta gaming)\n",
    "- Current topics have overlap. Expanding topic numbers may be needed.\n",
    "- Further preprocessing text may be helpful.\n",
    "- Expanding the number of transcripts used decreases session specific bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_components = 10 #Topics To generate\n",
    "n = 10 #Transcripts to use\n",
    "max_df=0.01\n",
    "min_df=0.0001\n",
    "n_terms = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_multi(n=25):\n",
    "    list_of_text = []\n",
    "    dir = 'data/aligned data/c=4'\n",
    "\n",
    "    files = [filename for filename in os.listdir(dir)]\n",
    "    sampled_files = random.choices(files,k=n)\n",
    "\n",
    "    for filename in sampled_files:\n",
    "        # choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+filename)\n",
    "        data = json.load(f)\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "\n",
    "        for x in data:\n",
    "            for y in x['TURNS']:\n",
    "                text = ' '.join(y['UTTERANCES'])\n",
    "                list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27330, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to tonight's episode of Critical Role,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Before we get into tonight's story, welcome. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's out for PS4, Xbox One, and PC. The latest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're cultists?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Welcome to tonight's episode of Critical Role,...\n",
       "1  Before we get into tonight's story, welcome. W...\n",
       "2                                           So good.\n",
       "3  It's out for PS4, Xbox One, and PC. The latest...\n",
       "4                                   You're cultists?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df_multi(n)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Count Vectorizer\n",
    "- Tfidf Vectorizer\n",
    "\n",
    "Use both with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27330, 5636)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27320</th>\n",
       "      <th>27321</th>\n",
       "      <th>27322</th>\n",
       "      <th>27323</th>\n",
       "      <th>27324</th>\n",
       "      <th>27325</th>\n",
       "      <th>27326</th>\n",
       "      <th>27327</th>\n",
       "      <th>27328</th>\n",
       "      <th>27329</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zolezzo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooming</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zsundie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9      \\\n",
       "zolezzo    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombie     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombies    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zooming    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zsundie    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         ...  27320  27321  27322  27323  27324  27325  27326  27327  27328  \\\n",
       "zolezzo  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombie   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombies  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zooming  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zsundie  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         27329  \n",
       "zolezzo    0.0  \n",
       "zombie     0.0  \n",
       "zombies    0.0  \n",
       "zooming    0.0  \n",
       "zsundie    0.0  \n",
       "\n",
       "[5 rows x 27330 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf=TfidfVectorizer(stop_words='english',max_df=.7,min_df=2,token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "tfidf_sparse = tfidf.fit_transform(df[0])\n",
    "print(tfidf_sparse.shape)\n",
    "tfidf_df = pd.DataFrame(tfidf_sparse.toarray().transpose(),\n",
    "                   index=tfidf.get_feature_names_out())\n",
    "tfidf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27330, 5636)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27320</th>\n",
       "      <th>27321</th>\n",
       "      <th>27322</th>\n",
       "      <th>27323</th>\n",
       "      <th>27324</th>\n",
       "      <th>27325</th>\n",
       "      <th>27326</th>\n",
       "      <th>27327</th>\n",
       "      <th>27328</th>\n",
       "      <th>27329</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zolezzo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooming</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zsundie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9      \\\n",
       "zolezzo      0      0      0      0      0      0      0      0      0      0   \n",
       "zombie       0      0      0      0      0      0      0      0      0      0   \n",
       "zombies      0      0      0      0      0      0      0      0      0      0   \n",
       "zooming      0      0      0      0      0      0      0      0      0      0   \n",
       "zsundie      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "         ...  27320  27321  27322  27323  27324  27325  27326  27327  27328  \\\n",
       "zolezzo  ...      0      0      0      0      0      0      0      0      0   \n",
       "zombie   ...      0      0      0      0      0      0      0      0      0   \n",
       "zombies  ...      0      0      0      0      0      0      0      0      0   \n",
       "zooming  ...      0      0      0      0      0      0      0      0      0   \n",
       "zsundie  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "         27329  \n",
       "zolezzo      0  \n",
       "zombie       0  \n",
       "zombies      0  \n",
       "zooming      0  \n",
       "zsundie      0  \n",
       "\n",
       "[5 rows x 27330 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "cv_sparse = cv.fit_transform(df[0])\n",
    "print(cv_sparse.shape)\n",
    "cv_df = pd.DataFrame(cv_sparse.toarray().transpose(),\n",
    "                   index=cv.get_feature_names_out())\n",
    "cv_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_terms(n_components, topics, terms, n_terms = 10):\n",
    "    for x in range(n_components):\n",
    "        topic = x\n",
    "        components = topics[:,topic]\n",
    "        top_term_indices = components.argsort()[-n_components:]\n",
    "        top_terms = np.array(terms)[top_term_indices]\n",
    "        \n",
    "        print(f'Topic {x}:\\t{top_terms.tolist()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['familiar', 'begin', 'fjord', 'hand', 'eyes', 'city', 'left', 'water', 'stone', 'body']\n",
      "Topic 1:\t['vanishes', 'glance', 'forward', 'flesh', 'familiar', 'skin', 'pool', 'eyes', 'stone', 'body']\n",
      "Topic 2:\t['half', 'center', 'arms', 'girl', 'table', 'small', 'room', 'man', 'begins', 'begin']\n",
      "Topic 3:\t['second', 'body', 'orb', 'cultists', 'deeper', 'thar', 'amphala', 'gathered', 'tower', 'city']\n",
      "Topic 4:\t['members', 'elite', 'familiar', 'family', 'taken', 'trying', 'left', 'keg', 'shepherds', 'iron']\n",
      "Topic 5:\t['century', 'produce', 'worship', 'local', 'crown', 'trostenwald', 'town', 'near', 'empire', 'small']\n",
      "Topic 6:\t['walking', 'wall', 'number', 'making', 'table', 'door', 'harbor', 'light', 'beautiful', 'lighthouse']\n",
      "Topic 7:\t['awesome', 'tuesday', 'week', 'new', 'tonight', 'episode', 'thank', 'twitch', 'role', 'critical']\n",
      "Topic 8:\t['decided', 'merrow', 'brief', 'action', 'seen', 'cali', 'safe', 'tunnel', 'left', 'house']\n",
      "Topic 9:\t['black', 'hear', 'darkness', 'shadows', 'dark', 'hand', 'room', 'gustav', 'lights', 'table']\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['yep', 'armor', 'strike', 'sneak', 'seven', 'definitely', 'natural', 'second', 'plus', 'hits']\n",
      "Topic 1:\t['seven', 'wait', 'man', 'fucking', 'natural', 'damn', 'thank', 'plus', 'god', 'fuck']\n",
      "Topic 2:\t['amazing', 'didn', 'rolled', 'seven', 'wait', 'fucking', 'plus', 'damn', 'thank', 'god']\n",
      "Topic 3:\t['level', 'action', 'second', 'bonus', 'rolled', 'sorry', 'wait', 'seven', 'natural', 'plus']\n",
      "Topic 4:\t['day', 'help', 'night', 'coming', 'great', 'love', 'man', 'nice', 'sam', 'thank']\n",
      "Topic 5:\t['fucking', 'man', 'second', 'thought', 'hold', 'action', 'didn', 'natural', 'sorry', 'wait']\n",
      "Topic 6:\t['sorry', 'second', 'luck', 'great', 'god', 'break', 'nott', 'rolled', 'cheering', 'natural']\n",
      "Topic 7:\t['big', 'bonus', 'didn', 'perception', 'action', 'nice', 'nott', 'great', 'fine', 'sorry']\n",
      "Topic 8:\t['fucking', 'action', 'gonna', 'nott', 'didn', 'perception', 'great', 'ooh', 'nice', 'fine']\n",
      "Topic 9:\t['bonus', 'cool', 'nott', 'great', 'action', 'ooh', 'fucking', 'advantage', 'perception', 'nice']\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['heard', 'gold', 'terrible', 'ask', 'dead', 'gets', 'grog', 'guy', 'tower', 'nott']\n",
      "Topic 1:\t['pulls', 'everybody', 'brings', 'idea', 'rope', 'ship', 'ooh', 'holding', 'stay', 'god']\n",
      "Topic 2:\t['correct', 'sutan', 'richter', 'horses', 'isn', 'giant', 'able', 'catch', 'moving', 'quite']\n",
      "Topic 3:\t['healing', 'damn', 'ulog', 'righty', 'step', 'cool', 'said', 'keg', 'far', 'door']\n",
      "Topic 4:\t['round', 'role', 'dice', 'bring', 'distance', 'critical', 'molly', 'advantage', 'direction', 'trying']\n",
      "Topic 5:\t['trinket', 'doesn', 'remember', 'boat', 'seeing', 'sounds', 'walking', 'person', 'percy', 'fine']\n",
      "Topic 6:\t['sense', 'saying', 'real', 'manage', 'hour', 'kill', 'used', 'yasha', 'bad', 'fucking']\n",
      "Topic 7:\t['cat', 'singing', 'standing', 'range', 'says', 'horse', 'wanted', 'definitely', 'great', 'thank']\n",
      "Topic 8:\t['happens', 'sondur', 'constitution', 'plan', 'shot', 'disadvantage', 'keyleth', 'wait', 'hits', 'sorry']\n",
      "Topic 9:\t['question', 'send', 'evening', 'wow', 'yep', 'ready', 'hey', 'level', 'gonna', 'lot']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['fast', 'body', 'saying', 'moving', 'correct', 'person', 'definitely', 'ends', 'place', 'advantage']\n",
      "Topic 1:\t['haven', 'rope', 'total', 'athletics', 'gone', 'gets', 'tower', 'molly', 'yasha', 'perception']\n",
      "Topic 2:\t['die', 'best', 'inside', 'house', 'walk', 'stealth', 'scanlan', 'wow', 'hey', 'rolled']\n",
      "Topic 3:\t['idea', 'fuck', 'high', 'throw', 'bad', 'trying', 'spell', 'fine', 'sorry', 'god']\n",
      "Topic 4:\t['singing', 'round', 'healing', 'used', 'attacks', 'yep', 'ooh', 'gonna', 'seven', 'big']\n",
      "Topic 5:\t['cart', 'corner', 'wrong', 'counting', 'ulog', 'straight', 'mind', 'nope', 'getting', 'better']\n",
      "Topic 6:\t['ship', 'talking', 'day', 'investigation', 'work', 'close', 'thought', 'doesn', 'lot', 'man']\n",
      "Topic 7:\t['armor', 'sounds', 'percy', 'dice', 'laughs', 'damn', 'magic', 'righty', 'keg', 'water']\n",
      "Topic 8:\t['making', 'plan', 'ah', 'dead', 'leave', 'said', 'cool', 'great', 'nice', 'hits']\n",
      "Topic 9:\t['ask', 'save', 'course', 'seen', 'frumpkin', 'disadvantage', 'true', 'kill', 'end', 'bonus']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['begins', 'fjord', 'hand', 'begin', 'eyes', 'water', 'body', 'stone', 'left', 'city']\n",
      "Topic 1:\t['vanishes', 'glance', 'forward', 'flesh', 'skin', 'familiar', 'pool', 'eyes', 'stone', 'body']\n",
      "Topic 2:\t['information', 'elemental', 'zsundie', 'jester', 'body', 'stone', 'individual', 'algar', 'water', 'fjord']\n",
      "Topic 3:\t['second', 'body', 'orb', 'cultists', 'deeper', 'gathered', 'thar', 'amphala', 'tower', 'city']\n",
      "Topic 4:\t['members', 'elite', 'familiar', 'family', 'taken', 'trying', 'left', 'keg', 'shepherds', 'iron']\n",
      "Topic 5:\t['eyes', 'face', 'orc', 'arms', 'pole', 'half', 'voice', 'toad', 'devil', 'girl']\n",
      "Topic 6:\t['coming', 'wall', 'number', 'making', 'harbor', 'table', 'door', 'light', 'beautiful', 'lighthouse']\n",
      "Topic 7:\t['awesome', 'tuesday', 'week', 'new', 'episode', 'tonight', 'thank', 'twitch', 'role', 'critical']\n",
      "Topic 8:\t['decided', 'strange', 'merrow', 'brief', 'seen', 'cali', 'safe', 'tunnel', 'left', 'house']\n",
      "Topic 9:\t['black', 'darkness', 'hear', 'shadows', 'dark', 'hand', 'room', 'gustav', 'lights', 'table']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['yep', 'armor', 'strike', 'sneak', 'seven', 'definitely', 'natural', 'second', 'plus', 'hits']\n",
      "Topic 1:\t['nice', 'wait', 'man', 'fucking', 'natural', 'damn', 'thank', 'plus', 'god', 'fuck']\n",
      "Topic 2:\t['trying', 'amazing', 'rolled', 'wait', 'seven', 'fucking', 'plus', 'damn', 'thank', 'god']\n",
      "Topic 3:\t['rolled', 'thank', 'second', 'bonus', 'action', 'sorry', 'wait', 'seven', 'natural', 'plus']\n",
      "Topic 4:\t['sorry', 'fine', 'great', 'natural', 'nott', 'sam', 'man', 'wait', 'nice', 'thank']\n",
      "Topic 5:\t['big', 'action', 'nott', 'man', 'natural', 'fine', 'nice', 'didn', 'sorry', 'wait']\n",
      "Topic 6:\t['sorry', 'fucking', 'nice', 'ooh', 'great', 'man', 'rolled', 'beau', 'cheering', 'natural']\n",
      "Topic 7:\t['bonus', 'great', 'cool', 'big', 'action', 'nice', 'nott', 'fine', 'didn', 'sorry']\n",
      "Topic 8:\t['doesn', 'nott', 'perception', 'didn', 'advantage', 'bonus', 'great', 'nice', 'action', 'fine']\n",
      "Topic 9:\t['beau', 'far', 'ooh', 'great', 'advantage', 'bonus', 'didn', 'perception', 'action', 'nice']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['hand', 'zsundie', 'information', 'met', 'elemental', 'jester', 'individual', 'algar', 'water', 'fjord']\n",
      "Topic 1:\t['forward', 'gone', 'night', 'hand', 'water', 'pool', 'familiar', 'eyes', 'stone', 'body']\n",
      "Topic 2:\t['orc', 'arms', 'voice', 'eyes', 'man', 'devil', 'toad', 'half', 'girl', 'begins']\n",
      "Topic 3:\t['second', 'discovered', 'orb', 'cultists', 'deeper', 'thar', 'amphala', 'gathered', 'tower', 'city']\n",
      "Topic 4:\t['taken', 'managed', 'family', 'trying', 'run', 'left', 'keg', 'city', 'shepherds', 'iron']\n",
      "Topic 5:\t['worship', 'local', 'trostenwald', 'crown', 'near', 'town', 'slowly', 'small', 'empire', 'begin']\n",
      "Topic 6:\t['wall', 'walking', 'buildings', 'ocean', 'docks', 'beautiful', 'city', 'tower', 'harbor', 'lighthouse']\n",
      "Topic 7:\t['awesome', 'tuesday', 'week', 'new', 'episode', 'tonight', 'thank', 'twitch', 'role', 'critical']\n",
      "Topic 8:\t['brief', 'strange', 'number', 'seen', 'taken', 'cali', 'tunnel', 'safe', 'left', 'house']\n",
      "Topic 9:\t['hand', 'light', 'lights', 'dark', 'door', 'begins', 'hear', 'room', 'begin', 'table']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=500)\n",
    "topics = nmf.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['class', 'misses', 'barely', 'yep', 'armor', 'strike', 'sneak', 'definitely', 'second', 'hits']\n",
      "Topic 1:\t['ooh', 'sake', 'gonna', 'ah', 'cheering', 'fucking', 'jester', 'gil', 'man', 'fuck']\n",
      "Topic 2:\t['cool', 'terrible', 'better', 'didn', 'rolled', 'amazing', 'trying', 'fucking', 'damn', 'god']\n",
      "Topic 3:\t['dex', 'action', 'rolled', 'modifier', 'second', 'bonus', 'ooh', 'level', 'seven', 'plus']\n",
      "Topic 4:\t['day', 'better', 'help', 'night', 'great', 'coming', 'love', 'man', 'sam', 'thank']\n",
      "Topic 5:\t['action', 'big', 'doesn', 'wrong', 'man', 'hold', 'minutes', 'thought', 'didn', 'wait']\n",
      "Topic 6:\t['high', 'saving', 'body', 'throw', 'luck', 'break', 'second', 'rolled', 'cheering', 'natural']\n",
      "Topic 7:\t['saving', 'throw', 'bonus', 'beau', 'door', 'didn', 'action', 'great', 'nott', 'sorry']\n",
      "Topic 8:\t['sounds', 'didn', 'half', 'leave', 'water', 'gonna', 'door', 'nott', 'great', 'fine']\n",
      "Topic 9:\t['work', 'cool', 'man', 'advantage', 'fucking', 'ooh', 'bonus', 'action', 'perception', 'nice']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=200)\n",
    "topics = nmf.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('metis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279e2d64b6cb4063ab7cfccb2020b604cfa41abe39379e7173718ec353138e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
