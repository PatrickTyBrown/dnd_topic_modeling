{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2E032_4_3.json\n"
     ]
    }
   ],
   "source": [
    "dir = 'data/aligned data/c=4'\n",
    "choice = random.choice(os.listdir(dir))\n",
    "print(choice)\n",
    "f = open(dir+'/'+choice)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CHUNK', 'ALIGNMENT', 'TURNS'])\n",
      "dict_keys(['NAMES', 'UTTERANCES', 'NUMBER'])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].keys())\n",
    "print(data[5]['TURNS'][0].keys())\n",
    "# print(data[5]['TURNS'][0]['UTTERANCES'])\n",
    "# print(' '.join(data[5]['TURNS'][0]['UTTERANCES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2612, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello everyone, and welcome to tonight's episo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's what we do!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's Dungeons &amp; Dragons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You will find out, Liam. He who ran it earlier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Bonegrinder.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Hello everyone, and welcome to tonight's episo...\n",
       "1                                 That's what we do!\n",
       "2                         What's Dungeons & Dragons?\n",
       "3  You will find out, Liam. He who ran it earlier...\n",
       "4                                   The Bonegrinder."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df(data=data):\n",
    "    list_of_text = []\n",
    "    for x in data:\n",
    "        for y in x['TURNS']:\n",
    "            text = ' '.join(y['UTTERANCES'])\n",
    "            list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df\n",
    "df = create_df(data=data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2E001_4_0.json\n",
      "C1E075_4_3.json\n",
      "C1E103_4_2.json\n",
      "C1E035_4_0.json\n",
      "C1E061_4_1.json\n",
      "C2E023_4_1.json\n",
      "C1E102_4_0.json\n",
      "C2E017_4_0.json\n",
      "C1E107_4_0.json\n",
      "C1E068_4_2.json\n",
      "C1E056_4_2.json\n",
      "C1E036_4_0.json\n",
      "C1E011_4_2.json\n",
      "C1E032_4_0.json\n",
      "C1E006_4_2.json\n",
      "C1E002_4_3.json\n",
      "C1E061_4_3.json\n",
      "C1E018_4_1.json\n",
      "C1E091_4_0.json\n",
      "C1E014_4_2.json\n",
      "C1E005_4_1.json\n",
      "C1E073_4_3.json\n",
      "C2E030_4_1.json\n",
      "C1E103_4_1.json\n",
      "C2E005_4_1.json\n",
      "C1E093_4_0.json\n",
      "C1E098_4_3.json\n",
      "C2E043_4_0.json\n",
      "C1E075_4_1.json\n",
      "C1E046_4_1.json\n",
      "C2E030_4_1.json\n",
      "C1E043_4_2.json\n",
      "C1E076_4_1.json\n",
      "C2E033_4_1.json\n",
      "C2E012_4_3.json\n",
      "C1E034_4_2.json\n",
      "C2E016_4_0.json\n",
      "C2E013_4_2.json\n",
      "C1E022_4_0.json\n",
      "C2E031_4_3.json\n",
      "C1E009_4_0.json\n",
      "C1E047_4_3.json\n",
      "C2E002_4_3.json\n",
      "C1E092_4_2.json\n",
      "C1E095_4_1.json\n",
      "C1E063_4_3.json\n",
      "C1E010_4_2.json\n",
      "C1E109_4_2.json\n",
      "C1E010_4_3.json\n",
      "C2E013_4_2.json\n",
      "C1E032_4_1.json\n",
      "C2E014_4_1.json\n",
      "C1E076_4_2.json\n",
      "C1E057_4_0.json\n",
      "C1E031_4_2.json\n",
      "C1E102_4_3.json\n",
      "C1E004_4_1.json\n",
      "C2E012_4_3.json\n",
      "C1E028_4_0.json\n",
      "C2E014_4_2.json\n",
      "C2E039_4_2.json\n",
      "C2E016_4_0.json\n",
      "C1E110_4_2.json\n",
      "C2E003_4_1.json\n",
      "C1E049_4_0.json\n",
      "C1E052_4_0.json\n",
      "C2E029_4_2.json\n",
      "C1E010_4_2.json\n",
      "C1E093_4_1.json\n",
      "C1E094_4_3.json\n",
      "C2E042_4_2.json\n",
      "C2E028_4_3.json\n",
      "C2E029_4_1.json\n",
      "C2E031_4_3.json\n",
      "C1E042_4_2.json\n",
      "C1E008_4_2.json\n",
      "C1E052_4_0.json\n",
      "C1E102_4_1.json\n",
      "C2E020_4_0.json\n",
      "C1E094_4_2.json\n",
      "C1E056_4_2.json\n",
      "C2E003_4_1.json\n",
      "C2E029_4_3.json\n",
      "C1E093_4_0.json\n",
      "C1E036_4_3.json\n",
      "C2E029_4_1.json\n",
      "C2E007_4_0.json\n",
      "C1E091_4_0.json\n",
      "C1E112_4_1.json\n",
      "C1E031_4_0.json\n",
      "C2E035_4_0.json\n",
      "C2E044_4_3.json\n",
      "C2E004_4_3.json\n",
      "C2E042_4_0.json\n",
      "C2E006_4_0.json\n",
      "C1E073_4_1.json\n",
      "C1E050_4_2.json\n",
      "C1E075_4_3.json\n",
      "C1E027_4_0.json\n",
      "C1E088_4_1.json\n",
      "(131185, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, everyone, and welcome to Critical Role,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False start, offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's great. But yes, welcome. We have just a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mine's really long, Matt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okay, Sam's is really long. Speaking of which,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Hello, everyone, and welcome to Critical Role,...\n",
       "1                              False start, offense.\n",
       "2  It's great. But yes, welcome. We have just a c...\n",
       "3                          Mine's really long, Matt.\n",
       "4  Okay, Sam's is really long. Speaking of which,..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df_multi(n):\n",
    "    list_of_text = []\n",
    "    dir = 'data/aligned data/c=4'\n",
    "\n",
    "    for i in range(n):\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "\n",
    "        for x in data:\n",
    "            for y in x['TURNS']:\n",
    "                text = ' '.join(y['UTTERANCES'])\n",
    "                list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df\n",
    "df = create_df_multi(50)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131185, 15917)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = TfidfVectorizer(stop_words={'english'}, \n",
    "    max_df=0.001,\n",
    "    min_df=0.00001,\n",
    "    # norm='l1',\n",
    "    )\n",
    "doc_vec = cv.fit_transform(df[0])\n",
    "doc_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10242, 4587)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words={'english'}, \n",
    "    max_df=0.005,\n",
    "    min_df=0.0001,\n",
    "    # norm='l1',\n",
    "    )\n",
    "doc_vec = cv.fit_transform(df[0])\n",
    "doc_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15917, 131185)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>131175</th>\n",
       "      <th>131176</th>\n",
       "      <th>131177</th>\n",
       "      <th>131178</th>\n",
       "      <th>131179</th>\n",
       "      <th>131180</th>\n",
       "      <th>131181</th>\n",
       "      <th>131182</th>\n",
       "      <th>131183</th>\n",
       "      <th>131184</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zooming</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooms</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoran</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zorro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwei</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       \\\n",
       "zooming     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zooms       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zoran       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zorro       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zwei        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "         8       9       ...  131175  131176  131177  131178  131179  131180  \\\n",
       "zooming     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zooms       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zoran       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zorro       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zwei        0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "         131181  131182  131183  131184  \n",
       "zooming     0.0     0.0     0.0     0.0  \n",
       "zooms       0.0     0.0     0.0     0.0  \n",
       "zoran       0.0     0.0     0.0     0.0  \n",
       "zorro       0.0     0.0     0.0     0.0  \n",
       "zwei        0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 131185 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df = pd.DataFrame(doc_vec.toarray().transpose(),\n",
    "                   index=cv.get_feature_names())\n",
    "print(tf_df.shape)\n",
    "tf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_components = 50\n",
    "nmf_5 = NMF(n_components=n_components)\n",
    "topics = nmf_5.fit_transform(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "n_components = 5\n",
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_components = 10\n",
    "nmf_5 = NMF(n_components=n_components)\n",
    "topics = nmf_5.fit_transform(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13', 'eight', 'rolled', '12', '14', 'yep', '18', '17', '16', '19']\n",
      "['says', 'constitution', 'wisdom', '23', '25', 'correct', 'die', 'stay', 'nope', 'yep']\n",
      "['thought', 'fjord', 'constitution', '22', 'nott', 'righty', 'eight', '17', '14', '16']\n",
      "['rolled', 'nine', 'eight', '11', 'seven', '13', '12', '14', '17', '18']\n",
      "['nine', 'level', '25', 'stay', '24', 'seven', 'perception', 'rolled', '16', '18']\n",
      "['rolled', 'ooh', '11', 'perception', '21', 'seven', 'eight', '13', '12', '14']\n",
      "['disadvantage', 'passive', 'nine', 'investigation', 'frumpkin', 'ooh', 'rolled', '30', '13', 'perception']\n",
      "['vex', 'name', 'damn', 'talking', 'never', 'wow', 'perception', '13', 'love', 'true']\n",
      "['22', '23', 'seven', 'nine', '21', 'ooh', 'eight', '13', '11', '12']\n",
      "['nope', 'vex', 'wow', 'seven', 'nine', 'awesome', '24', 'ooh', '11', '13']\n",
      "['nott', 'rolled', '25', 'seven', '30', 'eight', 'wow', '11', '21', 'ooh']\n",
      "['plan', 'amazing', 'went', 'hey', 'idea', 'kill', '13', 'ooh', '12', 'wow']\n",
      "['disadvantage', '30', 'nine', 'correct', '21', 'kill', 'eight', 'seven', 'wow', '11']\n",
      "['course', 'gonna', 'nine', 'disadvantage', '22', 'seven', '13', 'wow', 'kill', '21']\n",
      "['talk', '24', 'vex', 'eight', 'nope', 'stay', '11', 'hey', 'ooh', 'kill']\n",
      "['talk', 'gonna', 'thought', '13', 'nott', '12', '21', '11', 'love', 'hey']\n",
      "['nott', '24', 'righty', '22', '23', 'love', 'nine', 'seven', 'hey', 'eight']\n",
      "['awesome', 'never', '22', 'stay', 'thought', 'disadvantage', '30', '25', '24', 'love']\n",
      "['idea', 'movement', 'righty', 'nott', 'damn', 'hey', '22', '24', '30', '25']\n",
      "['dead', 'vex', 'damn', '12', 'level', 'righty', 'rolled', 'talk', '24', 'seven']\n"
     ]
    }
   ],
   "source": [
    "def get_top_terms(topic, n_terms, topics=topics, terms=cv.get_feature_names_out()):\n",
    "    # get the topic components (i.e., term weights)\n",
    "    # components = nmf.components_[topic, :]\n",
    "    components = topics[:,topic]\n",
    "\n",
    "    # get term indices, sorted (descending) by topic weights\n",
    "    top_term_indices = components.argsort()[-n_terms:]\n",
    "    \n",
    "    # use the `terms` array to get the actual top terms\n",
    "    top_terms = np.array(terms)[top_term_indices]\n",
    "    \n",
    "    return top_terms.tolist()\n",
    "\n",
    "for x in range(n_components):\n",
    "    print(get_top_terms(x,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00', '10', '100', '10d6', '11', '12', '120', '127', '13', '1350',\n",
       "       ...\n",
       "       'yup', 'zanror', 'zenith', 'zenwick', 'zephra', 'zero', 'zombie',\n",
       "       'zone', 'zoomf', 'zopher'],\n",
       "      dtype='object', length=4587)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6849,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10242)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_5.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4587, 10)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6849, 7310)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('metis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279e2d64b6cb4063ab7cfccb2020b604cfa41abe39379e7173718ec353138e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
