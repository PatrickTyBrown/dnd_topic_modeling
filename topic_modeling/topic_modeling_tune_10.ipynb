{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "### Without Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 17:34:20.594186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-28 17:34:20.594260: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import spacy\n",
    "# import coreferee\n",
    "# nlp = spacy.load('en_core_web_trf')\n",
    "# nlp.add_pipe('coreferee')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5 #Topics To generate\n",
    "n = 20 #Transcripts to use\n",
    "max_df=20\n",
    "min_df=3\n",
    "n_terms = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = [\"CCONJ\",\"NUM\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"X\"]\n",
    "# pos = [\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CCONJ\",\"DET\",\"INTJ\",\"NOUN\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"VERB\",\"X\"]\n",
    "pos = [\"ADJ\",\"AUX\",\"CCONJ\",\"DET\",\"INTJ\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"X\"]\n",
    "def clean_text(text, coref = False, lemma = True, pos_exclusions = pos):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    if coref:\n",
    "        new_text = \"\"\n",
    "        for i  in range(len(doc)):\n",
    "            tokens = doc[i]\n",
    "            if doc._.coref_chains.resolve(tokens):\n",
    "                new_text += doc._.coref_chains.resolve(tokens)[0].text\n",
    "            else:\n",
    "                new_text += tokens.text\n",
    "            new_text+= \" \"\n",
    "        doc = nlp(new_text)\n",
    "    text = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in pos_exclusions:\n",
    "            text += token.lemma_ if lemma else token.text\n",
    "            text += \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_multi(n=25):\n",
    "    list_of_text = []\n",
    "    dir = 'data/aligned data/c=4'\n",
    "\n",
    "    files = [filename for filename in os.listdir(dir)]\n",
    "    sampled_files = random.choices(files,k=n)\n",
    "\n",
    "    for filename in sampled_files:\n",
    "        # choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+filename)\n",
    "        data = json.load(f)\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "\n",
    "        for x in data:\n",
    "            for y in x['TURNS']:\n",
    "                text = ' '.join(y['UTTERANCES'])\n",
    "\n",
    "                text = clean_text(text)\n",
    "                list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49539, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>laughter damn welcome to tonight episode of bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unfortunately down tonight get plague from nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almost have woman at table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>almost have back back back for while now so re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  laughter damn welcome to tonight episode of bu...\n",
       "1  unfortunately down tonight get plague from nee...\n",
       "2                                         just come \n",
       "3                        almost have woman at table \n",
       "4  almost have back back back for while now so re..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df_multi(n)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Count Vectorizer\n",
    "- Tfidf Vectorizer\n",
    "\n",
    "Use both with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49539, 3283)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49529</th>\n",
       "      <th>49530</th>\n",
       "      <th>49531</th>\n",
       "      <th>49532</th>\n",
       "      <th>49533</th>\n",
       "      <th>49534</th>\n",
       "      <th>49535</th>\n",
       "      <th>49536</th>\n",
       "      <th>49537</th>\n",
       "      <th>49538</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>youtube</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziggurat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zigzag</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      \\\n",
       "youtube     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ziggurat    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zigzag      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombie      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zone        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "          9      ...  49529  49530  49531  49532  49533  49534  49535  49536  \\\n",
       "youtube     0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ziggurat    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zigzag      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zombie      0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zone        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "          49537  49538  \n",
       "youtube     0.0    0.0  \n",
       "ziggurat    0.0    0.0  \n",
       "zigzag      0.0    0.0  \n",
       "zombie      0.0    0.0  \n",
       "zone        0.0    0.0  \n",
       "\n",
       "[5 rows x 49539 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf=TfidfVectorizer(stop_words='english',max_df=.7,min_df=2,token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "tfidf_sparse = tfidf.fit_transform(df[0])\n",
    "print(tfidf_sparse.shape)\n",
    "tfidf_df = pd.DataFrame(tfidf_sparse.toarray().transpose(),\n",
    "                   index=tfidf.get_feature_names_out())\n",
    "tfidf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49539, 3283)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49529</th>\n",
       "      <th>49530</th>\n",
       "      <th>49531</th>\n",
       "      <th>49532</th>\n",
       "      <th>49533</th>\n",
       "      <th>49534</th>\n",
       "      <th>49535</th>\n",
       "      <th>49536</th>\n",
       "      <th>49537</th>\n",
       "      <th>49538</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>youtube</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziggurat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zigzag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      \\\n",
       "youtube       0      0      0      0      0      0      0      0      0   \n",
       "ziggurat      0      0      0      0      0      0      0      0      0   \n",
       "zigzag        0      0      0      0      0      0      0      0      0   \n",
       "zombie        0      0      0      0      0      0      0      0      0   \n",
       "zone          0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "          9      ...  49529  49530  49531  49532  49533  49534  49535  49536  \\\n",
       "youtube       0  ...      0      0      0      0      0      0      0      0   \n",
       "ziggurat      0  ...      0      0      0      0      0      0      0      0   \n",
       "zigzag        0  ...      0      0      0      0      0      0      0      0   \n",
       "zombie        0  ...      0      0      0      0      0      0      0      0   \n",
       "zone          0  ...      0      0      0      0      0      0      0      0   \n",
       "\n",
       "          49537  49538  \n",
       "youtube       0      0  \n",
       "ziggurat      0      0  \n",
       "zigzag        0      0  \n",
       "zombie        0      0  \n",
       "zone          0      0  \n",
       "\n",
       "[5 rows x 49539 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "cv_sparse = cv.fit_transform(df[0])\n",
    "print(cv_sparse.shape)\n",
    "cv_df = pd.DataFrame(cv_sparse.toarray().transpose(),\n",
    "                   index=cv.get_feature_names_out())\n",
    "cv_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_terms(n_components, topics, terms, n_terms = 10):\n",
    "    for x in range(n_components):\n",
    "        topic = x\n",
    "        components = topics[:,topic]\n",
    "        top_term_indices = components.argsort()[-n_components:]\n",
    "        top_terms = np.array(terms)[top_term_indices]\n",
    "        \n",
    "        print(f'Topic {x}:\\t{top_terms.tolist()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22010/11162862.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint_top_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['risk', 'loud', 'nap', 'pray', 'ow', 'lesson', 'goodness', 'yay', 'math', 'earring']\n",
      "Topic 1:\t['rip', 'goodness', 'disengage', 'darling', 'squeak', 'goddamn', 'hm', 'scare', 'dryad', 'downstair']\n",
      "Topic 2:\t['prisoner', 'warhammer', 'downstairs', 'cannon', 'wink', 'brothel', 'alcohol', 'goddamn', 'fucker', 'math']\n",
      "Topic 3:\t['scare', 'math', 'troll', 'goddamn', 'barrack', 'bust', 'lesson', 'yay', 'alcohol', 'comment']\n",
      "Topic 4:\t['grit', 'cookie', 'oil', 'nap', 'loud', 'disengage', 'scoop', 'yay', 'hm', 'bust']\n",
      "Topic 5:\t['intimidation', 'disengage', 'stealthe', 'brothel', 'fucker', 'goodness', 'math', 'chicken', 'lesson', 'bust']\n",
      "Topic 6:\t['yay', 'bust', 'charm', 'copy', 'dryad', 'squeak', 'nap', 'alcohol', 'hm', 'fucker']\n",
      "Topic 7:\t['slot', 'bastard', 'scoop', 'rip', 'button', 'barrack', 'squeak', 'loud', 'fucker', 'disengage']\n",
      "Topic 8:\t['poof', 'pause', 'stomach', 'hm', 'stealthe', 'dryad', 'loud', 'disengage', 'alcohol', 'chicken']\n",
      "Topic 9:\t['prisoner', 'assist', 'lesson', 'yay', 'disengage', 'brothel', 'copy', 'nap', 'hm', 'squeak']\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['hood', 'dog', 'credit', 'confuse', 'glove', 'goddamn', 'lack', 'gauntlet', 'sake', 'compatriot']\n",
      "Topic 1:\t['foyer', 'scoot', 'stomach', 'halfling', 'chicken', 'fold', 'spray', 'bard', 'forgery', 'troll']\n",
      "Topic 2:\t['crownsguard', 'obelisk', 'patrol', 'dip', 'camera', 'scoop', 'herd', 'loud', 'clap', 'servant']\n",
      "Topic 3:\t['refer', 'foremost', 'stealthe', 'comment', 'study', 'port', 'react', 'bullet', 'flip', 'brazier']\n",
      "Topic 4:\t['rapier', 'downstair', 'engage', 'law', 'ow', 'treat', 'halve', 'demon', 'risk', 'gunshot']\n",
      "Topic 5:\t['halfway', 'endeavor', 'bastard', 'stake', 'fucker', 'outward', 'restore', 'location', 'disengage', 'alcohol']\n",
      "Topic 6:\t['forgive', 'territory', 'goal', 'cliff', 'theme', 'season', 'oil', 'panel', 'sinkhole', 'cleanse']\n",
      "Topic 7:\t['goodness', 'intimidation', 'elbow', 'rip', 'podcast', 'lesson', 'twitter', 'shave', 'cask', 'clothing']\n",
      "Topic 8:\t['hint', 'truly', 'bucket', 'separate', 'downstairs', 'dryad', 'scare', 'earring', 'mace', 'choke']\n",
      "Topic 9:\t['fence', 'cannon', 'wipe', 'caravan', 'slot', 'stairway', 'copy', 'squeak', 'enchant', 'revenge']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['swinge', 'thumb', 'rotate', 'gain', 'wink', 'flip', 'darling', 'troll', 'copy', 'alcohol']\n",
      "Topic 1:\t['dope', 'guys', 'midnight', 'rag', 'cancel', 'pair', 'gut', 'dip', 'scout', 'downstair']\n",
      "Topic 2:\t['rug', 'pause', 'demon', 'camera', 'react', 'risk', 'halve', 'rip', 'disengage', 'comment']\n",
      "Topic 3:\t['deserve', 'evocation', 'fury', 'swear', 'gap', 'caravan', 'assist', 'stake', 'season', 'loud']\n",
      "Topic 4:\t['knife', 'clap', 'bard', 'butt', 'treat', 'oil', 'yay', 'goddamn', 'lesson', 'math']\n",
      "Topic 5:\t['spray', 'proficiency', 'preparation', 'compatriot', 'meeting', 'divide', 'revenge', 'longsword', 'tickle', 'slot']\n",
      "Topic 6:\t['religion', 'tinker', 'difference', 'foremost', 'parchment', 'enchant', 'brothel', 'intimidation', 'dryad', 'fucker']\n",
      "Topic 7:\t['bullet', 'separate', 'prisoner', 'confuse', 'scoop', 'stealthe', 'barrack', 'choke', 'goodness', 'earring']\n",
      "Topic 8:\t['elbow', 'crownsguard', 'bastard', 'glove', 'cannon', 'cask', 'ow', 'downstairs', 'scare', 'nap']\n",
      "Topic 9:\t['cookie', 'button', 'plenty', 'sorcerer', 'charm', 'grit', 'hm', 'squeak', 'bust', 'chicken']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['forgive', 'jet', 'agreement', 'compound', 'celestial', 'awake', 'sinkhole', 'ankheg', 'cleanse', 'swarm']\n",
      "Topic 1:\t['height', 'clasp', 'lid', 'fold', 'fox', 'veil', 'swell', 'roil', 'mute', 'loss']\n",
      "Topic 2:\t['gala', 'joint', 'snuck', 'stance', 'demeanor', 'deem', 'pitfall', 'detonate', 'bash', 'forgery']\n",
      "Topic 3:\t['mood', 'wandering', 'banner', 'infiltrate', 'demand', 'sever', 'siege', 'colony', 'varn', 'k']\n",
      "Topic 4:\t['religion', 'southward', 'bond', 'amphitheater', 'outward', 'friendship', 'civilization', 'erathis', 'bench', 'dome']\n",
      "Topic 5:\t['introduce', 'replace', 'tal', 'dorei', 'truly', 'knack', 'champion', 'childhood', 'impression', 'headmaster']\n",
      "Topic 6:\t['hail', 'fiction', 'locate', 'explore', 'credit', 'devise', 'stack', 'stumble', 'dragonborn', 'guild']\n",
      "Topic 7:\t['scuffle', 'portrait', 'rocket', 'bat', 'devil', 'rakshasa', 'lattice', 'avert', 'transition', 'prison']\n",
      "Topic 8:\t['safely', 'creation', 'celebration', 'halt', 'decay', 'pilgrimage', 'civilization', 'quest', 'abomination', 'paladin']\n",
      "Topic 9:\t['terrify', 'dearly', 'killing', 'wrestling', 'pity', 'consult', 'accompany', 'rank', 'banish', 'herd']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['glove', 'crownsguard', 'stealthe', 'treat', 'chocolate', 'math', 'milk', 'dryad', 'chicken', 'earring']\n",
      "Topic 1:\t['scare', 'scoop', 'cannon', 'rip', 'chicken', 'disengage', 'goddamn', 'dryad', 'earring', 'downstair']\n",
      "Topic 2:\t['season', 'crownsguard', 'react', 'downstair', 'goodness', 'copy', 'hm', 'comment', 'lesson', 'math']\n",
      "Topic 3:\t['barrack', 'hm', 'darling', 'choke', 'goddamn', 'copy', 'chicken', 'disengage', 'bust', 'comment']\n",
      "Topic 4:\t['thumb', 'hm', 'oil', 'goodness', 'cookie', 'copy', 'alcohol', 'math', 'fucker', 'bust']\n",
      "Topic 5:\t['ow', 'tickle', 'squeak', 'alcohol', 'nap', 'dryad', 'goodness', 'hm', 'bust', 'lesson']\n",
      "Topic 6:\t['butt', 'halve', 'copy', 'disengage', 'dryad', 'nap', 'charm', 'squeak', 'alcohol', 'fucker']\n",
      "Topic 7:\t['glove', 'brothel', 'stealthe', 'charm', 'halve', 'goodness', 'rip', 'hm', 'alcohol', 'disengage']\n",
      "Topic 8:\t['liar', 'intimidation', 'disengage', 'troll', 'charm', 'copy', 'lesson', 'fucker', 'goddamn', 'hm']\n",
      "Topic 9:\t['button', 'plenty', 'halve', 'comment', 'react', 'yay', 'hm', 'barrack', 'squeak', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['forgive', 'jet', 'agreement', 'compound', 'celestial', 'awake', 'ankheg', 'sinkhole', 'cleanse', 'swarm']\n",
      "Topic 1:\t['height', 'clasp', 'lid', 'fold', 'fox', 'veil', 'swell', 'roil', 'mute', 'loss']\n",
      "Topic 2:\t['gala', 'joint', 'snuck', 'stance', 'demeanor', 'deem', 'pitfall', 'detonate', 'bash', 'forgery']\n",
      "Topic 3:\t['mood', 'wandering', 'infiltrate', 'demand', 'banner', 'sever', 'siege', 'varn', 'colony', 'k']\n",
      "Topic 4:\t['religion', 'civilization', 'southward', 'bond', 'amphitheater', 'outward', 'friendship', 'erathis', 'bench', 'dome']\n",
      "Topic 5:\t['introduce', 'replace', 'dorei', 'tal', 'truly', 'knack', 'champion', 'childhood', 'impression', 'headmaster']\n",
      "Topic 6:\t['hail', 'fiction', 'locate', 'explore', 'credit', 'devise', 'stack', 'stumble', 'dragonborn', 'guild']\n",
      "Topic 7:\t['represent', 'portrait', 'rocket', 'bat', 'devil', 'rakshasa', 'lattice', 'avert', 'transition', 'prison']\n",
      "Topic 8:\t['safely', 'celebration', 'creation', 'halt', 'decay', 'pilgrimage', 'quest', 'abomination', 'civilization', 'paladin']\n",
      "Topic 9:\t['dearly', 'kindness', 'killing', 'wrestling', 'pity', 'consult', 'accompany', 'rank', 'banish', 'herd']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=500)\n",
    "topics = nmf.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['salvation', 'seize', 'statue', 'rally', 'stranger', 'restore', 'chop', 'enchant', 'pray', 'earring']\n",
      "Topic 1:\t['massaging', 'cow', 'bond', 'bum', 'choke', 'chip', 'yay', 'chocolate', 'milk', 'downstair']\n",
      "Topic 2:\t['wreathe', 'wedge', 'deserve', 'timing', 'engage', 'bastard', 'activate', 'wrong', 'warhammer', 'math']\n",
      "Topic 3:\t['shark', 'wipe', 'hover', 'blink', 'poof', 'nap', 'breast', 'drown', 'globule', 'comment']\n",
      "Topic 4:\t['stock', 'debate', 'maker', 'prisoner', 'absolve', 'assassin', 'disengage', 'clanking', 'implication', 'bust']\n",
      "Topic 5:\t['chuck', 'betrayer', 'rob', 'cheat', 'admit', 'circus', 'treat', 'liar', 'thrower', 'lesson']\n",
      "Topic 6:\t['elbow', 'lure', 'fry', 'waffle', 'berry', 'rally', 'egg', 'poof', 'stomach', 'chicken']\n",
      "Topic 7:\t['creativity', 'disengage', 'haversack', 'foremost', 'clink', 'mead', 'mix', 'season', 'goodness', 'alcohol']\n",
      "Topic 8:\t['remnant', 'mug', 'skeleton', 'rating', 'respond', 'wheel', 'rescue', 'fucker', 'dryad', 'squeak']\n",
      "Topic 9:\t['origin', 'wise', 'audio', 'static', 'podcast', 'brooch', 'theme', 'download', 'nap', 'goddamn']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=200)\n",
    "topics = nmf.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('metis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279e2d64b6cb4063ab7cfccb2020b604cfa41abe39379e7173718ec353138e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
