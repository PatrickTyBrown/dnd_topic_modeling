{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "### Without Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 17:59:26.215100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-28 17:59:26.215146: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import spacy\n",
    "# import coreferee\n",
    "# nlp = spacy.load('en_core_web_trf')\n",
    "# nlp.add_pipe('coreferee')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 25 #Topics To generate\n",
    "n = 40 #Transcripts to use\n",
    "max_df=20\n",
    "min_df=3\n",
    "n_terms = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = [\"CCONJ\",\"NUM\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"X\"]\n",
    "# pos = [\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CCONJ\",\"DET\",\"INTJ\",\"NOUN\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"VERB\",\"X\"]\n",
    "pos = [\"ADJ\",\"AUX\",\"CCONJ\",\"DET\",\"INTJ\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"X\"]\n",
    "def clean_text(text, coref = False, lemma = True, pos_exclusions = pos):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    if coref:\n",
    "        new_text = \"\"\n",
    "        for i  in range(len(doc)):\n",
    "            tokens = doc[i]\n",
    "            if doc._.coref_chains.resolve(tokens):\n",
    "                new_text += doc._.coref_chains.resolve(tokens)[0].text\n",
    "            else:\n",
    "                new_text += tokens.text\n",
    "            new_text+= \" \"\n",
    "        doc = nlp(new_text)\n",
    "    text = \"\"\n",
    "    for token in doc:\n",
    "        if token.pos_ not in pos_exclusions:\n",
    "            text += token.lemma_ if lemma else token.text\n",
    "            text += \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_multi(n=25):\n",
    "    list_of_text = []\n",
    "    dir = 'data/aligned data/c=4'\n",
    "\n",
    "    files = [filename for filename in os.listdir(dir)]\n",
    "    sampled_files = random.choices(files,k=n)\n",
    "\n",
    "    for filename in sampled_files:\n",
    "        # choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+filename)\n",
    "        data = json.load(f)\n",
    "        choice = random.choice(os.listdir(dir))\n",
    "        # print(choice)\n",
    "        f = open(dir+'/'+choice)\n",
    "        data = json.load(f)\n",
    "\n",
    "        for x in data:\n",
    "            for y in x['TURNS']:\n",
    "                text = ' '.join(y['UTTERANCES'])\n",
    "\n",
    "                text = clean_text(text)\n",
    "                list_of_text.append(text)\n",
    "    df = pd.DataFrame(list_of_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105048, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome evening to show bunch of ass voice act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome back so first foremost get couple anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go worry about want apologize in advance to fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  welcome evening to show bunch of ass voice act...\n",
       "1  welcome back so first foremost get couple anno...\n",
       "2                                                so \n",
       "3                                          slightly \n",
       "4  go worry about want apologize in advance to fo..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df_multi(n)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Count Vectorizer\n",
    "- Tfidf Vectorizer\n",
    "\n",
    "Use both with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105048, 4191)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105038</th>\n",
       "      <th>105039</th>\n",
       "      <th>105040</th>\n",
       "      <th>105041</th>\n",
       "      <th>105042</th>\n",
       "      <th>105043</th>\n",
       "      <th>105044</th>\n",
       "      <th>105045</th>\n",
       "      <th>105046</th>\n",
       "      <th>105047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zigzag</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       \\\n",
       "zigzag     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zip        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zombie     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zone       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zoo        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        8       9       ...  105038  105039  105040  105041  105042  105043  \\\n",
       "zigzag     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zip        0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zombie     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zone       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "zoo        0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        105044  105045  105046  105047  \n",
       "zigzag     0.0     0.0     0.0     0.0  \n",
       "zip        0.0     0.0     0.0     0.0  \n",
       "zombie     0.0     0.0     0.0     0.0  \n",
       "zone       0.0     0.0     0.0     0.0  \n",
       "zoo        0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 105048 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf=TfidfVectorizer(stop_words='english',max_df=.7,min_df=2,token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "tfidf_sparse = tfidf.fit_transform(df[0])\n",
    "print(tfidf_sparse.shape)\n",
    "tfidf_df = pd.DataFrame(tfidf_sparse.toarray().transpose(),\n",
    "                   index=tfidf.get_feature_names_out())\n",
    "tfidf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105048, 4191)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105038</th>\n",
       "      <th>105039</th>\n",
       "      <th>105040</th>\n",
       "      <th>105041</th>\n",
       "      <th>105042</th>\n",
       "      <th>105043</th>\n",
       "      <th>105044</th>\n",
       "      <th>105045</th>\n",
       "      <th>105046</th>\n",
       "      <th>105047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zigzag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       \\\n",
       "zigzag       0       0       0       0       0       0       0       0   \n",
       "zip          0       0       0       0       0       0       0       0   \n",
       "zombie       0       0       0       0       0       0       0       0   \n",
       "zone         0       0       0       0       0       0       0       0   \n",
       "zoo          0       0       0       0       0       0       0       0   \n",
       "\n",
       "        8       9       ...  105038  105039  105040  105041  105042  105043  \\\n",
       "zigzag       0       0  ...       0       0       0       0       0       0   \n",
       "zip          0       0  ...       0       0       0       0       0       0   \n",
       "zombie       0       0  ...       0       0       0       0       0       0   \n",
       "zone         0       0  ...       0       0       0       0       0       0   \n",
       "zoo          0       0  ...       0       0       0       0       0       0   \n",
       "\n",
       "        105044  105045  105046  105047  \n",
       "zigzag       0       0       0       0  \n",
       "zip          0       0       0       0  \n",
       "zombie       0       0       0       0  \n",
       "zone         0       0       0       0  \n",
       "zoo          0       0       0       0  \n",
       "\n",
       "[5 rows x 105048 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english', \n",
    "    max_df=max_df,\n",
    "    min_df=min_df,\n",
    "    token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "cv_sparse = cv.fit_transform(df[0])\n",
    "print(cv_sparse.shape)\n",
    "cv_df = pd.DataFrame(cv_sparse.toarray().transpose(),\n",
    "                   index=cv.get_feature_names_out())\n",
    "cv_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_terms(n_components, topics, terms, n_terms = 10):\n",
    "    for x in range(n_components):\n",
    "        topic = x\n",
    "        components = topics[:,topic]\n",
    "        top_term_indices = components.argsort()[-n_terms:]\n",
    "        top_terms = np.array(terms)[top_term_indices]\n",
    "        \n",
    "        print(f'Topic {x}:\\t{top_terms.tolist()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['practitioner', 'greed', 'hoard', 'narrowly', 'mercy', 'contemplate', 'cling', 'creator', 'ceremony', 'looter']\n",
      "Topic 1:\t['combine', 'nostril', 'necessity', 'ware', 'sage', 'breeze', 'drape', 'ceremony', 'port', 'looter']\n",
      "Topic 2:\t['conclude', 'installation', 'inhale', 'invoke', 'parameter', 'eternity', 'completion', 'obligation', 'scribe', 'recipient']\n",
      "Topic 3:\t['flying', 'hike', 'manipulation', 'tradition', 'knack', 'meditate', 'childhood', 'truly', 'impression', 'headmaster']\n",
      "Topic 4:\t['potential', 'devise', 'abdoman', 'orcs', 'puzzle', 'reign', 'demand', 'devour', 'impression', 'headmaster']\n",
      "Topic 5:\t['kneel', 'brighten', 'intensity', 'atop', 'chip', 'stain', 'account', 'stillness', 'entryway', 'sanctuary']\n",
      "Topic 6:\t['recede', 'intersection', 'amphitheater', 'desperation', 'crossroad', 'speech', 'prayer', 'bond', 'erathis', 'bench']\n",
      "Topic 7:\t['commotion', 'snuck', 'cobra', 'midst', 'boon', 'purely', 'follower', 'masquerade', 'ti', 'yuan']\n",
      "Topic 8:\t['unfold', 'user', 'origin', 'subscription', 'subscribe', 'download', 'emote', 'tier', 'refresher', 'podcast']\n",
      "Topic 9:\t['tier', 'tapestry', 'refresher', 'ti', 'podcast', 'yuan', 'sapphire', 'arch', 'fortress', 'throne']\n",
      "Topic 10:\t['fortress', 'scuffle', 'bounty', 'membership', 'hunter', 'lodestone', 'resurrection', 'ramification', 'throne', 'carriage']\n",
      "Topic 11:\t['rove', 'screaming', 'unravel', 'imprison', 'underling', 'rebellion', 'undergo', 'infiltration', 'denizen', 'develop']\n",
      "Topic 12:\t['ramification', 'develop', 'toppling', 'penalty', 'method', 'dwindle', 'nonetheless', 'rift', 'resurrection', 'lodestone']\n",
      "Topic 13:\t['limp', 'unite', 'cherry', 'joy', 'loss', 'blossom', 'unlock', 'ceremony', 'acolyte', 'guidance']\n",
      "Topic 14:\t['chagrin', 'extract', 'umber', 'alignment', 'revenge', 'general', 'monstrosity', 'sorcerer', 'colony', 'offshoot']\n",
      "Topic 15:\t['specie', 'ruminate', 'roost', 'dominance', 'planning', 'slaughter', 'alter', 'spire', 'enslave', 'clan']\n",
      "Topic 16:\t['arriving', 'wreak', 'ire', 'bounty', 'burial', 'restroom', 'sunset', 'incursion', 'manticore', 'gnoll']\n",
      "Topic 17:\t['pump', 'basilisk', 'temporarily', 'pm', 'submerge', 'fighting', 'magma', 'edition', 'account', 'fortress']\n",
      "Topic 18:\t['tick', 'speck', 'sapphire', 'arch', 'submit', 'exclude', 'subscribe', 'pm', 'account', 'edition']\n",
      "Topic 19:\t['occupy', 'guise', 'scope', 'meditate', 'conclude', 'operation', 'semblance', 'scuffle', 'retreat', 'sundown']\n",
      "Topic 20:\t['glad', 'retreat', 'sundown', 'howl', 'resurrection', 'springtime', 'till', 'sleet', 'snowfall', 'orchard']\n",
      "Topic 21:\t['unravel', 'pew', 'howl', 'orchard', 'impression', 'headmaster', 'resurrection', 'dime', 'writhe', 'speck']\n",
      "Topic 22:\t['rely', 'writhe', 'orchard', 'wane', 'replacement', 'compatriot', 'completion', 'speck', 'lodestone', 'rift']\n",
      "Topic 23:\t['awake', 'scuffle', 'resurrection', 'mini', 'retreat', 'artist', 'sundown', 'dime', 'writhe', 'speck']\n",
      "Topic 24:\t['greeting', 'kingdom', 'fiction', 'explore', 'hail', 'mystery', 'dime', 'orchard', 'writhe', 'speck']\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['keg', 'mimic', 'text', 'grieve', 'socket', 'lycan', 'invisibility', 'toast', 'tary', 'eyeball']\n",
      "Topic 1:\t['sizzle', 'cake', 'y', 'disarm', 'marching', 'text', 'toast', 'vomit', 'gingerly', 'grieve']\n",
      "Topic 2:\t['tick', 'barrack', 'healer', 'queen', 'yesterday', 'grieve', 'tary', 'gingerly', 'locket', 'theater']\n",
      "Topic 3:\t['y', 'grieve', 'grace', 'keg', 'lately', 'mimic', 'text', 'gingerly', 'lycan', 'locket']\n",
      "Topic 4:\t['advisor', 'pen', 'tearfully', 'toast', 'theater', 'grieve', 'yesterday', 'invisibility', 'lately', 'lycan']\n",
      "Topic 5:\t['sizzle', 'tablet', 'okay', 'tary', 'gone', 'advisor', 'text', 'grieve', 'locket', 'invisibility']\n",
      "Topic 6:\t['disperse', 'alert', 'holding', 'queen', 'lycan', 'pen', 'lately', 'sure', 'invisibility', 'gingerly']\n",
      "Topic 7:\t['invisibility', 'grieve', 'mimic', 'bless', 'gone', 'locket', 'pen', 'toast', 'tary', 'lately']\n",
      "Topic 8:\t['bless', 'sure', 'grieve', 'text', 'mimic', 'invisibility', 'locket', 'tearfully', 'okay', 'pen']\n",
      "Topic 9:\t['advisor', 'invisibility', 'tick', 'healer', 'gingerly', 'toast', 'hex', 'warhammer', 'vomit', 'yesterday']\n",
      "Topic 10:\t['gingerly', 'warhammer', 'marry', 'sure', 'lycan', 'sizzle', 'gone', 'yesterday', 'tary', 'tearfully']\n",
      "Topic 11:\t['sharpshooter', 'bakery', 'holding', 'gingerly', 'healer', 'tearfully', 'mini', 'gone', 'mimic', 'toast']\n",
      "Topic 12:\t['lycan', 'invisibility', 'advisor', 'gone', 'queen', 'toast', 'vomit', 'tearfully', 'keg', 'text']\n",
      "Topic 13:\t['edition', 'advisor', 'invisibility', 'marching', 'drown', 'tearfully', 'keg', 'vomit', 'mimic', 'sure']\n",
      "Topic 14:\t['advisor', 'sizzle', 'mimic', 'dmed', 'rpg', 'lately', 'tearfully', 'okay', 'holding', 'keg']\n",
      "Topic 15:\t['sure', 'sizzle', 'keg', 'delivery', 'hex', 'disarm', 'holding', 'warhammer', 'text', 'advisor']\n",
      "Topic 16:\t['butcher', 'deadeye', 'intentionally', 'tablet', 'sailor', 'disarm', 'warn', 'toast', 'keg', 'tearfully']\n",
      "Topic 17:\t['crouch', 'mimic', 'disperse', 'gone', 'closet', 'yesterday', 'dmed', 'rpg', 'tick', 'keg']\n",
      "Topic 18:\t['tearfully', 'tick', 'alert', 'sharpshooter', 'deadeye', 'okay', 'gingerly', 'mimic', 'lately', 'text']\n",
      "Topic 19:\t['vomit', 'goes', 'yesterday', 'levitate', 'tick', 'mini', 'hex', 'sure', 'sharpshooter', 'holding']\n",
      "Topic 20:\t['delivery', 'misfire', 'rpg', 'dmed', 'affection', 'affiliation', 'separately', 'queen', 'sure', 'advisor']\n",
      "Topic 21:\t['warn', 'tearfully', 'drown', 'tick', 'healer', 'tablet', 'sizzle', 'opposite', 'goes', 'closet']\n",
      "Topic 22:\t['bless', 'mimic', 'advice', 'sailor', 'sure', 'sneeze', 'marching', 'disarm', 'tick', 'queen']\n",
      "Topic 23:\t['advisor', 'okay', 'poo', 'sizzle', 'dmed', 'rpg', 'warn', 'marching', 'tick', 'goes']\n",
      "Topic 24:\t['dmed', 'disperse', 'drown', 'warhammer', 'duration', 'tablet', 'queen', 'y', 'holding', 'goes']\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "topics = pca.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['chatroom', 'beetle', 'hex', 'holding', 'toast', 'instantly', 'gesture', 'y', 'tablet', 'chant']\n",
      "Topic 1:\t['r', 'lately', 'lycan', 'nudge', 'headmaster', 'depth', 'eyeball', 'speech', 'stronghold', 'grey']\n",
      "Topic 2:\t['basis', 'gleam', 'rpg', 'spinning', 'flavor', 'barrack', 'investigate', 'text', 'component', 'guidance']\n",
      "Topic 3:\t['puzzle', 'keg', 'alert', 'electricity', 'bread', 'crouch', 'longsword', 'gash', 'loosely', 'vomit']\n",
      "Topic 4:\t['detect', 'clientele', 'tighten', 'rapidly', 'missile', 'moisture', 'queen', 'warn', 'lollipop', 'healer']\n",
      "Topic 5:\t['rally', 'estate', 'sailor', 'relic', 'maul', 'linger', 'sway', 'scare', 'obscure', 'marry']\n",
      "Topic 6:\t['caduceus', 'destination', 'lumber', 'sneeze', 'genuinely', 'drown', 'tary', 'bark', 'lemure', 'pew']\n",
      "Topic 7:\t['revenge', 'temperature', 'char', 'clay', 'goes', 'n', 'misfire', 'carriage', 'bath', 'mini']\n",
      "Topic 8:\t['hut', 'rebellion', 'stat', 'dawn', 'drain', 'loop', 'gingerly', 'alcohol', 'sundown', 'develop']\n",
      "Topic 9:\t['propose', 'casino', 'concern', 'louder', 'speck', 'pm', 'joy', 'yesterday', 'closet', 'mimic']\n",
      "Topic 10:\t['tearfully', 'merch', 'increase', 'ti', 'lung', 'steam', 'cling', 'okay', 'ceremony', 'ravine']\n",
      "Topic 11:\t['playlist', 'advice', 'abomination', 'grace', 'bakery', 'warhammer', 'sub', 'socket', 'gnoll', 'artist']\n",
      "Topic 12:\t['marching', 'gray', 'constantly', 'stance', 'physically', 'bargain', 'occur', 'theater', 'sharpshooter', 'orchard']\n",
      "Topic 13:\t['reform', 'role', 'submerge', 'sanctuary', 'promo', 'sizzle', 'throne', 'pole', 'caravan', 'fortress']\n",
      "Topic 14:\t['globe', 'correct', 'improve', 'exhaustion', 'rescue', 'hiding', 'majority', 'marker', 'puff', 'site']\n",
      "Topic 15:\t['cap', 'hum', 'surrounding', 'disperse', 'entertainment', 'tier', 'curtain', 'rifle', 'advisor', 'edition']\n",
      "Topic 16:\t['shh', 'witness', 'justice', 'makeup', 'sure', 'quake', 'percent', 'cousin', 'score', 'tick']\n",
      "Topic 17:\t['whatsoever', 'screw', 'squeak', 'bless', 'protrude', 'customer', 'disarm', 'fool', 'carving', 'shackle']\n",
      "Topic 18:\t['rust', 'dancing', 'pub', 'shade', 'legitimately', 'greatsword', 'stabilize', 'yank', 'furniture', 'pen']\n",
      "Topic 19:\t['void', 'jerky', 'clicking', 'cobblestone', 'outline', 'cake', 'gaming', 'weakness', 'accord', 'encampment']\n",
      "Topic 20:\t['rune', 'recipient', 'crop', 'adult', 'efreet', 'scribe', 'com', 'opinion', 'download', 'horizon']\n",
      "Topic 21:\t['topple', 'disturb', 'male', 'accomplish', 'logo', 'locket', 'disease', 'howl', 'rift', 'photo']\n",
      "Topic 22:\t['thug', 'decay', 'ripple', 'anchor', 'encase', 'proof', 'longbow', 'mail', 'podcast', 'walkway']\n",
      "Topic 23:\t['butcher', 'rate', 'value', 'gone', 'subscribe', 'cleave', 'intentionally', 'vary', 'invisibility', 'thousand']\n",
      "Topic 24:\t['punishment', 'enlarge', 'gag', 'clasp', 'divination', 'bastion', 'border', 'crumble', 'rag', 'quarry']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['vary', 'tether', 'pew', 'rag', 'necromancy', 'carving', 'lollipop', 'marching', 'yesterday', 'pen']\n",
      "Topic 1:\t['glad', 'grappling', 'kima', 'occasion', 'download', 'linger', 'efreet', 'maul', 'bless', 'tearfully']\n",
      "Topic 2:\t['backhand', 'tax', 'dancing', 'situate', 'wrong', 'signing', 'barrack', 'tablet', 'warn', 'disperse']\n",
      "Topic 3:\t['surrounding', 'rapidly', 'judgment', 'artist', 'relief', 'stink', 'alcohol', 'keg', 'sure', 'tary']\n",
      "Topic 4:\t['gas', 'gaming', 'obscure', 'latch', 'attune', 'vibrate', 'corrupt', 'mini', 'goes', 'mimic']\n",
      "Topic 5:\t['gnoll', 'stitch', 'electricity', 'weakness', 'stronghold', 'loosely', 'sundown', 'missile', 'opposite', 'percent']\n",
      "Topic 6:\t['lumber', 'schedule', 'octopus', 'fortress', 'stomp', 'exhaustion', 'cake', 'value', 'intentionally', 'toast']\n",
      "Topic 7:\t['male', 'compare', 'clicking', 'custom', 'fool', 'casting', 'occur', 'concern', 'pole', 'gone']\n",
      "Topic 8:\t['carriage', 'jug', 'digit', 'midnight', 'fortune', 'customer', 'instantly', 'duration', 'disease', 'casino']\n",
      "Topic 9:\t['clay', 'bread', 'caduceus', 'alert', 'abomination', 'drown', 'holding', 'sizzle', 'queen', 'text']\n",
      "Topic 10:\t['unlock', 'longbow', 'ac', 'ew', 'pub', 'deadeye', 'cleave', 'accord', 'flavor', 'sailor']\n",
      "Topic 11:\t['whatsoever', 'sprinter', 'molly', 'mistress', 'rate', 'joy', 'sadly', 'proof', 'sharpshooter', 'invisibility']\n",
      "Topic 12:\t['orchard', 'import', 'tank', 'cackle', 'dead', 'weaken', 'nightmare', 'stabilize', 'hiding', 'hex']\n",
      "Topic 13:\t['flurry', 'knickknack', 'manner', 'skirt', 'clatter', 'sub', 'walkway', 'crouch', 'butcher', 'advisor']\n",
      "Topic 14:\t['role', 'peanut', 'evocation', 'stance', 'rifle', 'poo', 'grace', 'component', 'cousin', 'okay']\n",
      "Topic 15:\t['divination', 'spoil', 'adult', 'scare', 'score', 'marry', 'tick', 'warhammer', 'lycan', 'gingerly']\n",
      "Topic 16:\t['vantage', 'bracer', 'handling', 'working', 'delivery', 'edition', 'bakery', 'opinion', 'sneeze', 'healer']\n",
      "Topic 17:\t['bastion', 'jerky', 'chatroom', 'bark', 'fang', 'activate', 'peel', 'dawn', 'closet', 'disarm']\n",
      "Topic 18:\t['communicate', 'drain', 'legitimately', 'yard', 'puff', 'user', 'bladestorm', 'chant', 'advice', 'misfire']\n",
      "Topic 19:\t['playlist', 'ravine', 'country', 'lure', 'badass', 'propose', 'lately', 'theater', 'locket', 'eyeball']\n",
      "Topic 20:\t['encase', 'clench', 'basis', 'hostage', 'tag', 'greatsword', 'lair', 'merch', 'quarry', 'grieve']\n",
      "Topic 21:\t['meteorite', 'gash', 'accomplish', 'shh', 'pepper', 'globe', 'beetle', 'squeak', 'levitate', 'nudge']\n",
      "Topic 22:\t['hum', 'crap', 'boost', 'diameter', 'steam', 'fighting', 'physically', 'longsword', 'stat', 'inhale']\n",
      "Topic 23:\t['mount', 'socket', 'fantasy', 'louder', 'detect', 'scrying', 'sale', 'mail', 'increase', 'marker']\n",
      "Topic 24:\t['clockwork', 'award', 'gesture', 'talking', 'bargain', 'investigate', 'genuinely', 'disturb', 'y', 'vomit']\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "topics = lda.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['contemplate', 'ware', 'cling', 'sage', 'breeze', 'port', 'creator', 'drape', 'ceremony', 'looter']\n",
      "Topic 1:\t['practitioner', 'greed', 'hoard', 'narrowly', 'mercy', 'contemplate', 'cling', 'creator', 'ceremony', 'looter']\n",
      "Topic 2:\t['conclude', 'installation', 'inhale', 'invoke', 'parameter', 'eternity', 'completion', 'obligation', 'scribe', 'recipient']\n",
      "Topic 3:\t['flying', 'hike', 'manipulation', 'tradition', 'knack', 'meditate', 'childhood', 'truly', 'impression', 'headmaster']\n",
      "Topic 4:\t['divergence', 'den', 'potential', 'abdoman', 'devise', 'orcs', 'puzzle', 'reign', 'demand', 'devour']\n",
      "Topic 5:\t['apex', 'brighten', 'intensity', 'chip', 'atop', 'stain', 'account', 'stillness', 'entryway', 'sanctuary']\n",
      "Topic 6:\t['recede', 'intersection', 'amphitheater', 'desperation', 'crossroad', 'speech', 'prayer', 'bond', 'erathis', 'bench']\n",
      "Topic 7:\t['snuck', 'cobra', 'midst', 'boon', 'purely', 'follower', 'carriage', 'masquerade', 'ti', 'yuan']\n",
      "Topic 8:\t['unfold', 'user', 'origin', 'subscription', 'subscribe', 'download', 'emote', 'tier', 'refresher', 'podcast']\n",
      "Topic 9:\t['balcony', 'sex', 'pupil', 'magma', 'tapestry', 'sorcerer', 'sapphire', 'arch', 'fortress', 'throne']\n",
      "Topic 10:\t['bedroom', 'kingdom', 'scuffle', 'bounty', 'membership', 'hunter', 'lodestone', 'resurrection', 'ramification', 'carriage']\n",
      "Topic 11:\t['rove', 'screaming', 'unravel', 'imprison', 'underling', 'rebellion', 'undergo', 'infiltration', 'denizen', 'develop']\n",
      "Topic 12:\t['undergo', 'ramification', 'toppling', 'penalty', 'method', 'dwindle', 'nonetheless', 'rift', 'resurrection', 'lodestone']\n",
      "Topic 13:\t['limp', 'unite', 'cherry', 'joy', 'loss', 'blossom', 'unlock', 'ceremony', 'acolyte', 'guidance']\n",
      "Topic 14:\t['chagrin', 'extract', 'umber', 'monstrosity', 'alignment', 'revenge', 'general', 'sorcerer', 'colony', 'offshoot']\n",
      "Topic 15:\t['specie', 'roost', 'ruminate', 'dominance', 'planning', 'slaughter', 'alter', 'spire', 'enslave', 'clan']\n",
      "Topic 16:\t['arriving', 'wreak', 'ire', 'burial', 'bounty', 'restroom', 'sunset', 'incursion', 'manticore', 'gnoll']\n",
      "Topic 17:\t['basilisk', 'temporarily', 'submerge', 'fighting', 'edition', 'account', 'magma', 'retreat', 'sundown', 'fortress']\n",
      "Topic 18:\t['artist', 'sapphire', 'arch', 'submit', 'exclude', 'orchard', 'subscribe', 'pm', 'account', 'edition']\n",
      "Topic 19:\t['occupy', 'guise', 'scope', 'meditate', 'conclude', 'operation', 'semblance', 'scuffle', 'retreat', 'sundown']\n",
      "Topic 20:\t['outsider', 'reception', 'birth', 'youth', 'warm', 'royalty', 'fortune', 'sibling', 'capital', 'orchard']\n",
      "Topic 21:\t['mystery', 'thousand', 'stain', 'resurrection', 'pew', 'springtime', 'till', 'sleet', 'snowfall', 'orchard']\n",
      "Topic 22:\t['overall', 'greeting', 'kingdom', 'fiction', 'explore', 'hail', 'mystery', 'dime', 'writhe', 'speck']\n",
      "Topic 23:\t['wane', 'replacement', 'fiction', 'explore', 'compatriot', 'hail', 'completion', 'kingdom', 'lodestone', 'rift']\n",
      "Topic 24:\t['afford', 'miniature', 'highly', 'dime', 'lodestone', 'artist', 'writhe', 'rift', 'mini', 'speck']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['component', 'tablet', 'holding', 'warn', 'keg', 'tary', 'gone', 'gingerly', 'invisibility', 'eyeball']\n",
      "Topic 1:\t['nudge', 'deadeye', 'sadly', 'invisibility', 'mimic', 'text', 'theater', 'queen', 'tary', 'grieve']\n",
      "Topic 2:\t['holding', 'gone', 'warn', 'dmed', 'rpg', 'grieve', 'invisibility', 'theater', 'locket', 'lycan']\n",
      "Topic 3:\t['disarm', 'drown', 'sure', 'badass', 'y', 'invisibility', 'vomit', 'tearfully', 'gingerly', 'theater']\n",
      "Topic 4:\t['instantly', 'warhammer', 'disarm', 'mimic', 'pen', 'sure', 'yesterday', 'gingerly', 'grieve', 'locket']\n",
      "Topic 5:\t['locket', 'gone', 'disperse', 'y', 'disarm', 'lately', 'vomit', 'mimic', 'gingerly', 'invisibility']\n",
      "Topic 6:\t['marching', 'warn', 'queen', 'text', 'opposite', 'gone', 'toast', 'lately', 'gingerly', 'lycan']\n",
      "Topic 7:\t['disperse', 'advisor', 'tablet', 'y', 'lately', 'marching', 'locket', 'toast', 'vomit', 'tary']\n",
      "Topic 8:\t['rpg', 'advisor', 'casino', 'sure', 'marching', 'sailor', 'pen', 'okay', 'vomit', 'text']\n",
      "Topic 9:\t['yesterday', 'theater', 'invisibility', 'bless', 'hex', 'warn', 'sneeze', 'gone', 'pen', 'toast']\n",
      "Topic 10:\t['closet', 'bakery', 'pen', 'okay', 'hex', 'mimic', 'tary', 'sizzle', 'lately', 'gone']\n",
      "Topic 11:\t['tearfully', 'mimic', 'tick', 'badass', 'goes', 'toast', 'locket', 'sizzle', 'tary', 'text']\n",
      "Topic 12:\t['missile', 'disease', 'sure', 'keg', 'lycan', 'vomit', 'healer', 'tary', 'sizzle', 'pen']\n",
      "Topic 13:\t['vomit', 'pen', 'opinion', 'lair', 'grace', 'marching', 'gone', 'advisor', 'tearfully', 'mimic']\n",
      "Topic 14:\t['pm', 'tearfully', 'edition', 'mimic', 'gone', 'healer', 'bless', 'toast', 'queen', 'sure']\n",
      "Topic 15:\t['sneeze', 'sure', 'marry', 'advisor', 'tick', 'tearfully', 'disease', 'tary', 'keg', 'goes']\n",
      "Topic 16:\t['misfire', 'yesterday', 'sneeze', 'marching', 'tick', 'gone', 'drown', 'text', 'vomit', 'keg']\n",
      "Topic 17:\t['warn', 'toast', 'okay', 'delivery', 'yesterday', 'dawn', 'disease', 'marching', 'sizzle', 'advisor']\n",
      "Topic 18:\t['queen', 'toast', 'lately', 'bladestorm', 'stabilize', 'drown', 'dmed', 'rpg', 'healer', 'tick']\n",
      "Topic 19:\t['nudge', 'holding', 'disperse', 'mimic', 'dmed', 'rpg', 'toast', 'mini', 'warhammer', 'keg']\n",
      "Topic 20:\t['healer', 'pen', 'merch', 'misfire', 'lollipop', 'signing', 'disperse', 'goes', 'marching', 'queen']\n",
      "Topic 21:\t['holding', 'lure', 'butcher', 'accord', 'flavor', 'sizzle', 'disperse', 'value', 'tearfully', 'hex']\n",
      "Topic 22:\t['rpg', 'dmed', 'hex', 'bakery', 'marching', 'marry', 'holding', 'queen', 'nudge', 'duration']\n",
      "Topic 23:\t['evocation', 'yank', 'sure', 'divination', 'sadly', 'necromancy', 'abomination', 'mini', 'marching', 'y']\n",
      "Topic 24:\t['advice', 'closet', 'opposite', 'bless', 'yard', 'dawn', 'advisor', 'signing', 'disperse', 'queen']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n_components)\n",
    "topics = svd.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\t['barker', 'storefront', 'combine', 'nostril', 'necessity', 'drape', 'breeze', 'ware', 'sage', 'port']\n",
      "Topic 1:\t['creator', 'practitioner', 'greed', 'hoard', 'narrowly', 'mercy', 'contemplate', 'ceremony', 'cling', 'looter']\n",
      "Topic 2:\t['conclude', 'installation', 'inhale', 'invoke', 'parameter', 'eternity', 'completion', 'obligation', 'scribe', 'recipient']\n",
      "Topic 3:\t['childhood', 'expectation', 'tradition', 'flying', 'hike', 'manipulation', 'meditate', 'truly', 'impression', 'headmaster']\n",
      "Topic 4:\t['nameless', 'divergence', 'potential', 'den', 'abdoman', 'orcs', 'puzzle', 'reign', 'demand', 'devour']\n",
      "Topic 5:\t['recovery', 'guardian', 'kneel', 'intensity', 'brighten', 'chip', 'stain', 'stillness', 'entryway', 'sanctuary']\n",
      "Topic 6:\t['recede', 'intersection', 'amphitheater', 'desperation', 'crossroad', 'speech', 'prayer', 'bond', 'erathis', 'bench']\n",
      "Topic 7:\t['commotion', 'snuck', 'creator', 'cobra', 'midst', 'boon', 'purely', 'follower', 'ti', 'yuan']\n",
      "Topic 8:\t['unfold', 'subscribe', 'user', 'origin', 'subscription', 'download', 'emote', 'tier', 'refresher', 'podcast']\n",
      "Topic 9:\t['overlook', 'balcony', 'multitude', 'breeze', 'sex', 'pupil', 'tapestry', 'sapphire', 'arch', 'throne']\n",
      "Topic 10:\t['northeast', 'status', 'farmer', 'northwest', 'scuffle', 'bounty', 'bedroom', 'hunter', 'membership', 'carriage']\n",
      "Topic 11:\t['rove', 'infiltration', 'screaming', 'denizen', 'unravel', 'imprison', 'underling', 'rebellion', 'undergo', 'develop']\n",
      "Topic 12:\t['completion', 'ramification', 'toppling', 'method', 'penalty', 'dwindle', 'nonetheless', 'rift', 'resurrection', 'lodestone']\n",
      "Topic 13:\t['limp', 'unite', 'cherry', 'joy', 'loss', 'blossom', 'unlock', 'acolyte', 'ceremony', 'guidance']\n",
      "Topic 14:\t['chagrin', 'arcanist', 'extract', 'sorcerer', 'alignment', 'umber', 'revenge', 'general', 'monstrosity', 'colony']\n",
      "Topic 15:\t['specie', 'ruminate', 'roost', 'dominance', 'planning', 'slaughter', 'alter', 'spire', 'enslave', 'clan']\n",
      "Topic 16:\t['wreak', 'ire', 'burial', 'denizen', 'restroom', 'bounty', 'sunset', 'incursion', 'manticore', 'gnoll']\n",
      "Topic 17:\t['kidnap', 'pump', 'basilisk', 'temporarily', 'sorcerer', 'submerge', 'fighting', 'magma', 'throne', 'fortress']\n",
      "Topic 18:\t['subscription', 'unlock', 'subject', 'artist', 'submit', 'exclude', 'subscribe', 'pm', 'edition', 'account']\n",
      "Topic 19:\t['outsider', 'reception', 'childhood', 'birth', 'youth', 'warm', 'royalty', 'sibling', 'fortune', 'capital']\n",
      "Topic 20:\t['occupy', 'scope', 'infiltration', 'conclude', 'meditate', 'operation', 'semblance', 'scuffle', 'retreat', 'sundown']\n",
      "Topic 21:\t['descent', 'fermentation', 'vegetation', 'glad', 'bough', 'till', 'springtime', 'sleet', 'snowfall', 'orchard']\n",
      "Topic 22:\t['diplomacy', 'appoint', 'ruse', 'overall', 'greeting', 'fiction', 'explore', 'kingdom', 'hail', 'mystery']\n",
      "Topic 23:\t['caress', 'lamprey', 'ichor', 'decay', 'needle', 'encase', 'thud', 'dime', 'writhe', 'speck']\n",
      "Topic 24:\t['representation', 'simulacrum', 'minis', 'plastic', 'launch', 'afford', 'dollar', 'miniature', 'highly', 'mini']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=500)\n",
    "topics = nmf.fit_transform(cv_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22973/1313570337.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint_top_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, W, H)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massume_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         self.reconstruction_err_ = _beta_divergence(\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, W, H, update_H)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             W, H, n_iter = _fit_coordinate_descent(\n\u001b[0m\u001b[1;32m   1604\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                 \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_fit_coordinate_descent\u001b[0;34m(X, W, H, tol, max_iter, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose, shuffle, random_state)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# Update H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             violation += _update_coordinate_descent(\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_update_coordinate_descent\u001b[0;34m(X, W, Ht, l1_reg, l2_reg, shuffle, random_state)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;31m# The following seems to be required on 64-bit Windows w/ Python 3.5.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0mpermutation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_update_cdnmf_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, max_iter=400)\n",
    "topics = nmf.fit_transform(tfidf_df)\n",
    "print_top_terms(n_components=n_components, topics=topics, terms=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('metis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2279e2d64b6cb4063ab7cfccb2020b604cfa41abe39379e7173718ec353138e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
